<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
	<head>
		<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />

		<title>Steffen Frey</title>
		<link rel="stylesheet" type="text/css" media="screen" href="rw_common/themes/aqualicious/styles.css"  />
		<link rel="stylesheet" type="text/css" media="print" href="rw_common/themes/aqualicious/print.css"  />
		<link rel="stylesheet" type="text/css" media="handheld" href="rw_common/themes/aqualicious/handheld.css"  />
		<link rel="stylesheet" type="text/css" media="screen" href="rw_common/themes/aqualicious/css/styles/blue.css" />
		<link rel="stylesheet" type="text/css" media="screen" href="rw_common/themes/aqualicious/css/highlight/off.css" />
		<link rel="stylesheet" type="text/css" media="screen" href="rw_common/themes/aqualicious/css/sidebar/sidebar_hide.css" />
		<link rel="stylesheet" type="text/css" media="screen" href="rw_common/themes/aqualicious/css/font/modern.css" />
		<link rel="stylesheet" type="text/css" media="screen" href="rw_common/themes/aqualicious/css/background/white.css" />
		<link rel="stylesheet" type="text/css" media="screen" href="rw_common/themes/aqualicious/css/width/1000.css" />




		<script type="text/javascript" src="rw_common/themes/aqualicious/javascript.js"></script>


				<link rel='stylesheet' type='text/css' media='all' href='rw_common/plugins/stacks/stacks.css' />
		<!--[if lte IE 7]>
			<link rel='stylesheet' type='text/css' media='all' href='rw_common/plugins/stacks/stacks_ie.css' />
		<![endif]-->
		<link rel='stylesheet' type='text/css' media='all' href='files/stacks_page_page0.css' />
		<script type='text/javascript' charset='utf-8' src='files/stacks_page_page0.js'></script>



	</head>
<body>
<!-- <div id="gradient"></div> -->
<!-- <div id="navcontainer"><\!-- Start Navigation -\-> -->

<!-- </div><\!-- End navigation -\-> -->

<div id="container"><!-- Start container -->
	<div id="pageHeader"><!-- Start page header -->

		<h1>High Performance Scientific Visualization</h1>
		<!-- <h2>Visualizations Research Institute of the University of Stuttgart (VISUS)</h2> -->
		<!-- <h2> <a href=https://www.rug.nl/?lang=en>University of Groningen</a></h2>  -->
		<h2>University of Groningen</h2>
	</div><!-- End page header -->

	<div id="sidebarContainer"><!-- Start Sidebar wrapper -->
		<div id="sidebar"><!-- Start sidebar content -->
			<h1 class="sideHeader"></h1><!-- Sidebar header -->
			 <br /><!-- sidebar content you enter in the page inspector -->
			 <!-- sidebar content such as the blog archive links -->
		</div><!-- End sidebar content -->
	</div><!-- End sidebar wrapper -->

	<div id="contentContainer"><!-- Start main content wrapper -->
		<div id="content"><!-- Start content -->
			<div class="contentSpacer"></div><!-- this makes sure the content is long enough for the design -->


			<!-- Stacks v1188 --><div id='stacks_out_0_page0' class='stacks_top'><div id='stacks_in_0_page0' class=''><div id='stacks_out_261_page0' class='stacks_out'><div id='stacks_in_261_page0' class='stacks_in '><div id='stacks_out_262_page0' class='stacks_out'><div id='stacks_in_262_page0' class='stacks_in stack_stack'><div id='stacks_out_264_page0' class='stacks_out'><div id='stacks_in_264_page0' class='stacks_in stack_stack'><div id='stacks_out_266_page0' class='stacks_out'><div id='stacks_in_266_page0' class='stacks_in stack_stack'><div id='stacks_out_244_page0' class='stacks_out'><div id='stacks_in_244_page0' class='stacks_in text_stack'><span id='stacks_in_245_page0'>
						  <strong>Steffen Frey</strong></span></div></div><div id='stacks_out_409_page0' class='stacks_out'><div id='stacks_in_409_page0' class='stacks_in text_stack'>
						Assistant Professor (Tenure Track)<br />
						<a href=https://www.rug.nl/?lang=en>University of Groningen</a> <br /><br /></div></div><div id='stacks_out_411_page0' class='stacks_out'><div id='stacks_in_411_page0' class='stacks_in text_stack'>
						Room 456<br />Nijenborgh 9 (Bernoulliborg)<br />9747 AG  Groningen<br />Netherlands</div></div>
					    <div id='stacks_out_414_page0' class='stacks_out'>
					      <div id='stacks_in_414_page0' class='stacks_in text_stack'>
						<!-- Tel.: +49 (0)711 685-88629<br /> -->
						<a href="mailto:s.d.frey@rug.nl">s.d.frey@rug.nl</a>
						<br /><br />
						<a href="cv/cv_frey.pdf">Curriculum Vitae (CV)</a>
					</div></div></div></div><div id='stacks_out_272_page0' class='stacks_out'><div id='stacks_in_272_page0' class='stacks_in stack_stack'><div id='stacks_out_280_page0' class='stacks_out'><div id='stacks_in_280_page0' class='stacks_in image_stack'><div class='centered_image' ><img class='imageStyle' src='files/stacks_image_281.jpg' width='210'  alt='Stacks Image 281' /></div></div></div></div></div></div></div></div></div></div></div><div id='stacks_out_19_page0' class='stacks_out'><div id='stacks_in_19_page0' class='stacks_in text_stack'>
				<!-- <a href="#research_overview">Research</a> | <a href="#service">Service</a> | <a href="#teaching">Teaching</a> -->
				My research concerns the development of methods to gain insights from large quantities of data, addressing both cognitive and technical limitations. This involves different directions of research which are tightly connected, including machine learning /optimization, high performance visualization (distributed/parallel approaches, in situ visualization), and multifield visualization.
			    </div></div><div id='stacks_out_989_page0' class='stacks_out'><div id='stacks_in_989_page0' class='stacks_in text_stack'><span id='stacks_in_990_page0'><a name="research_overview">Publications</a></span></div></div>


			    <!-- <div id='stacks_out_250_page0' class='stacks_out'><div id='stacks_in_250_page0' class='stacks_in text_stack'> -->
			    <!-- 	The purpose of scientific visualization is to graphically illustrate scientific data, enabling scientists to gain new insights and a deeper understanding. The size and complexity of these data sets are continuously increasing with new simulation and data acquisition methods as well as growing hardware processing power. Visualization needs to be able scale with the data, and therefore itself needs to develop new illustration techniques in conjunction with novel approaches harness the huge processing power of parallel environments.<br /><br />To accomplish this goal, I develop new approaches for the efficient usage of parallel environments (in particular GPUs and clusters) as well as the illustration of the data, with the main goal being the integration of both aspects. While the emphasis is more on one or the other depending on the specific objective, neither component may be completely neglected to achieve both expressive and responsive visualization. My dissertation from 2014 addresses <a href="papers/diss_digital_opt.pdf">Strategies for efficient parallel visualization</a>.<br /> -->
			    <!-- 	<br /> -->

		<!-- We developed the TRRojan framework for systematic empirical evaluation of the performance of visual computing algorithms. The TRRojan is designed to effectively carry out quantitative benchmarks in a clean, reproducible, and easy-to-use manner. It uses a plugin architecture for simple extensibility with additional applications. The framework as open source software (MIT licence), the data we obtained during measurements, as well as additional information can be found <a href="http://trrojan.visus.uni-stuttgart.de">on this website</a>. -->
			    </div></div>

			    <!-- header year			     -->
			    <div id='stacks_out_9_page0' class='stacks_out'><div id='stacks_in_9_page0' class='stacks_in text_stack'><span id='stacks_in_10_page0'>2020</span></div></div>

			    <!-- <ul> -->
			      <!--   <li>flo ldav (tvcg)</li> -->			      
			    <!--   <li>in situ vis chapter</li> -->
			   
			      <!-- </ul> -->

			    <!-- begin paper-->

			    <div id='stacks_out_1357_page0' class='stacks_out'><div id='stacks_in_1357_page0' class='stacks_in '><div id='stacks_out_1358_page0' class='stacks_out'><div id='stacks_in_1358_page0' class='stacks_in stack_stack'><div id='stacks_out_1360_page0' class='stacks_out'><div id='stacks_in_1360_page0' class='stacks_in stack_stack'><div id='stacks_out_1362_page0' class='stacks_out'><div id='stacks_in_1362_page0' class='stacks_in stack_stack'>

					    <!-- pics here begin -->
					    <div id='stacks_out_1364_page0' class='stacks_out'><div id='stacks_in_1364_page0' class='stacks_in image_stack'><div class='centered_image' ><img class='imageStyle' src='pics/foveated_high_res_illu.png' width='290' alt='Stacks Image 1365' /></div></div></div>
					    <!-- <div id='stacks_out_1364_page0' class='stacks_out'><div id='stacks_in_1364_page0' class='stacks_in image_stack'><div class='centered_image' ><img class='imageStyle' src='pics/gaze_kite.png' width='300' alt='Stacks Image 1365' /></div></div></div> -->

					    <!-- <div id='stacks_out_1366_page0' class='stacks_out'><div id='stacks_in_1366_page0' class='stacks_in image_stack'><div class='centered_image' ><img class='imageStyle' src='files/stacks_image_1367.png' width='300' height='150' alt='Stacks Image 1367' /></div></div></div> -->

					    <!-- <div id='stacks_out_1366_page0' class='stacks_out'><div id='stacks_in_1366_page0' class='stacks_in image_stack'><div class='centered_image' ><img class='imageStyle' src='pics/ev18/bottle.png' width='250' alt='Stacks Image 1367' /></div></div></div> -->
					    <!-- pics here end -->

				    </div></div>


					<div id='stacks_out_1368_page0' class='stacks_out'><div id='stacks_in_1368_page0' class='stacks_in stack_stack'><div id='stacks_out_1370_page0' class='stacks_out'><div id='stacks_in_1370_page0' class='stacks_in text_stack'><span id='stacks_in_1371_page0'>
						  <strong>Foveated Encoding for Large High-Resolution Displays</strong>
					    </span></div></div><div id='stacks_out_1372_page0' class='stacks_out'><div id='steacks_in_1372_page0' class='stacks_in text_stack'>
						<!-- authors here -->
						<em>F. Frieß, M. Braun, V. Bruder, S. Frey, G. Reina, T. Ertl</em>
					      </div></div><div id='stacks_out_1374_page0' class='stacks_out'><div id='stacks_in_1374_page0' class='stacks_in text_stack'>
						<!-- DOI: <a href="https://"></a>10.1109/TVCG.2020.3030445<br /> -->
						     DOI: 10.1109/TVCG.2020.3030445 <em>(to appear)</em><br />
						  <a href="https://www.computer.org/csdl/journal/tg">IEEE Transactions on Visualization and Computer Graphic</a><br/>
					    </div></div><div id='stacks_out_1376_page0' class='stacks_out'><div id='stacks_in_1376_page0' class='stacks_in text_stack'>
						<!-- abstract here begin -->
						    Collaborative exploration of scientific data sets across large high-resolution displays requires both high visual detail as well as low-latency transfer of image data (oftentimes inducing the need to trade one for the other). In this work, we present a system that dynamically adapts the encoding quality in such systems in a way that reduces the required bandwidth without impacting the details perceived by one or more observers. Humans perceive sharp, colourful details, in the small foveal region around the centre of the field of view, while information in the periphery is perceived blurred and colourless. We account for this by tracking the gaze of observers, and respectively adapting the quality parameter of each macroblock used by the H.264 encoder, considering the so-called visual acuity fall-off. This allows to substantially reduce the required bandwidth with barely noticeable changes in visual quality, which is crucial for collaborative analysis across display walls at different locations. We demonstrate the reduced overall required bandwidth and the high quality inside the foveated regions using particle rendering and parallel coordinates.
						<!-- abstract here end -->
					    </div></div><div id='stacks_out_1378_page0' class='stacks_out'><div id='stacks_in_1378_page0' class='stacks_in text_stack'>
						<!-- <a href="bibs/tlic.bib">[bib]</a> -->
						<!-- <a href="papers/tlic.pdf">[pdf]</a> -->
						<a href="videos/foveated_high_res.mp4">[video]</a>
						<br />
			    </div></div></div></div></div></div></div></div></div></div><div id='stacks_out_1032_page0' class='stacks_out'>				

			      <!-- end paper-->
			      
			    <!-- begin paper-->

			    <div id='stacks_out_1357_page0' class='stacks_out'><div id='stacks_in_1357_page0' class='stacks_in '><div id='stacks_out_1358_page0' class='stacks_out'><div id='stacks_in_1358_page0' class='stacks_in stack_stack'><div id='stacks_out_1360_page0' class='stacks_out'><div id='stacks_in_1360_page0' class='stacks_in stack_stack'><div id='stacks_out_1362_page0' class='stacks_out'><div id='stacks_in_1362_page0' class='stacks_in stack_stack'>

					    <!-- pics here begin -->
					    <div id='stacks_out_1364_page0' class='stacks_out'><div id='stacks_in_1364_page0' class='stacks_in image_stack'><div class='centered_image' ><img class='imageStyle' src='pics/tlic_bottle.png' width='290' alt='Stacks Image 1365' /></div></div></div>
					    <!-- <div id='stacks_out_1364_page0' class='stacks_out'><div id='stacks_in_1364_page0' class='stacks_in image_stack'><div class='centered_image' ><img class='imageStyle' src='pics/gaze_kite.png' width='300' alt='Stacks Image 1365' /></div></div></div> -->

					    <!-- <div id='stacks_out_1366_page0' class='stacks_out'><div id='stacks_in_1366_page0' class='stacks_in image_stack'><div class='centered_image' ><img class='imageStyle' src='files/stacks_image_1367.png' width='300' height='150' alt='Stacks Image 1367' /></div></div></div> -->

					    <!-- <div id='stacks_out_1366_page0' class='stacks_out'><div id='stacks_in_1366_page0' class='stacks_in image_stack'><div class='centered_image' ><img class='imageStyle' src='pics/ev18/bottle.png' width='250' alt='Stacks Image 1367' /></div></div></div> -->
					    <!-- pics here end -->

				    </div></div>


					<div id='stacks_out_1368_page0' class='stacks_out'><div id='stacks_in_1368_page0' class='stacks_in stack_stack'><div id='stacks_out_1370_page0' class='stacks_out'><div id='stacks_in_1370_page0' class='stacks_in text_stack'><span id='stacks_in_1371_page0'>
						  <strong>Temporally Dense Exploration of Moving and Deforming Shapes</strong>
					    </span></div></div><div id='stacks_out_1372_page0' class='stacks_out'><div id='steacks_in_1372_page0' class='stacks_in text_stack'>
						<!-- authors here -->
						<em>S. Frey</em>
					      </div></div><div id='stacks_out_1374_page0' class='stacks_out'><div id='stacks_in_1374_page0' class='stacks_in text_stack'>
						   DOI: <a href="https://doi.org/10.1111/cgf.14092">10.1111/cgf.14092</a><br />
						  <a href="https://www.computer.org/csdl/magazine/cg">Computer Graphics Forum</a><br/>
					    </div></div><div id='stacks_out_1376_page0' class='stacks_out'><div id='stacks_in_1376_page0' class='stacks_in text_stack'>
						<!-- abstract here begin -->
						We present our approach for the dense visualization and temporal exploration of moving and deforming shapes from scientific experiments and simulations. Our image space representation is created by convolving a noise texture along shape contours (akin to LIC). Beyond indicating spatial structure via luminosity, we additionally use colour to depict time or classes of shapes via automatically customized maps. This representation summarizes temporal evolution, and provides the basis for interactive user navigation in the spatial and temporal domain in combination with traditional renderings. Our efficient implementation supports the quick and progressive generation of our representation in parallel as well as adaptive temporal splits to reduce overlap. We discuss and demonstrate the utility of our approach using 2D and 3D scalar fields from experiments and simulations.
						<!-- abstract here end -->
					    </div></div><div id='stacks_out_1378_page0' class='stacks_out'><div id='stacks_in_1378_page0' class='stacks_in text_stack'>
						<a href="bibs/tlic.bib">[bib]</a>
						<a href="papers/tlic.pdf">[pdf]</a>
						<a href="videos/tlic_interaction.mp4">[video]</a>
						<br />
			    </div></div></div></div></div></div></div></div></div></div><div id='stacks_out_1032_page0' class='stacks_out'>				

			      <!-- end paper-->
			      
			    <!-- begin paper-->

			    <div id='stacks_out_1357_page0' class='stacks_out'><div id='stacks_in_1357_page0' class='stacks_in '><div id='stacks_out_1358_page0' class='stacks_out'><div id='stacks_in_1358_page0' class='stacks_in stack_stack'><div id='stacks_out_1360_page0' class='stacks_out'><div id='stacks_in_1360_page0' class='stacks_in stack_stack'><div id='stacks_out_1362_page0' class='stacks_out'><div id='stacks_in_1362_page0' class='stacks_in stack_stack'>

					    <!-- pics here begin -->
					    <div id='stacks_out_1364_page0' class='stacks_out'><div id='stacks_in_1364_page0' class='stacks_in image_stack'><div class='centered_image' ><img class='imageStyle' src='pics/ch11-perf-load_balancing.png' width='300' alt='Stacks Image 1365' /></div></div></div>
					    <div id='stacks_out_1364_page0' class='stacks_out'><div id='stacks_in_1364_page0' class='stacks_in image_stack'><div class='centered_image' ><img class='imageStyle' src='pics/ch11-vdi_illus.png' width='300' alt='Stacks Image 1365' /></div></div></div>

					    <!-- <div id='stacks_out_1366_page0' class='stacks_out'><div id='stacks_in_1366_page0' class='stacks_in image_stack'><div class='centered_image' ><img class='imageStyle' src='files/stacks_image_1367.png' width='300' height='150' alt='Stacks Image 1367' /></div></div></div> -->

					    <!-- <div id='stacks_out_1366_page0' class='stacks_out'><div id='stacks_in_1366_page0' class='stacks_in image_stack'><div class='centered_image' ><img class='imageStyle' src='pics/ev18/bottle.png' width='250' alt='Stacks Image 1367' /></div></div></div> -->
					    <!-- pics here end -->

				    </div></div>


					<div id='stacks_out_1368_page0' class='stacks_out'><div id='stacks_in_1368_page0' class='stacks_in stack_stack'><div id='stacks_out_1370_page0' class='stacks_out'><div id='stacks_in_1370_page0' class='stacks_in text_stack'><span id='stacks_in_1371_page0'>
						  <strong>Trade-offs and Parameter Adaptation in In Situ Visualization</strong>
					    </span></div></div><div id='stacks_out_1372_page0' class='stacks_out'><div id='steacks_in_1372_page0' class='stacks_in text_stack'>
						<!-- authors here -->
						<em>S. Frey, V. Bruder, F. Frieß, P. Gralka, T. Rau, T. Ertl, G. Reina</em>
					      </div></div><div id='stacks_out_1374_page0' class='stacks_out'><div id='stacks_in_1374_page0' class='stacks_in text_stack'>						
						Chapter in the book <em>In Situ Visualization for Computational Science</em> (Publisher: Springer)
						<!-- <a href="https://www.computer.org/csdl/magazine/cg">Computer Graphics Forum</a><br/> -->
					    </div></div><div id='stacks_out_1376_page0' class='stacks_out'><div id='stacks_in_1376_page0' class='stacks_in text_stack'>
						<!-- abstract here begin -->
						This chapter discusses trade-offs and parameter tuning in in situ visualization, with an emphasis on rendering quality and workload distribution.
 Four different use cases are analyzed with respect to the characteristics of configuration changes, and the design as well as dynamic adaptation choices following from this. First, the performance impact of load balancing and resource allocation variants on the simulation and the visualization is investigated using the visualization framework MegaMol. Its loose coupling scheme and architecture enable minimally invasive in situ operation without impacting the stability of the simulation with (potentially) experimental visualization code. Second, Volumetric Depth Images (VDIs) are considered: a compact, view-dependent intermediate representation that can efficiently be generated and used for a posteriori exploration. A study of their inherent trade-offs regarding size, quality, and generation time provides the basis for parameter optimization. Third, streaming for remote visualization allows a user to monitor the progress of the simulation and to steer visualization parameters. Compression settings are adapted dynamically based on predictions via convolutional neural networks across different parts of images to achieve high frame rates for high-resolution displays like powerwalls. Fourth, different performance prediction models for volume rendering address offline scenarios (like hardware acquisition planning) as well as dynamic adaptation of parameters and load balancing. Finally, the chapter concludes by summarizing overarching approaches and challenges, and discussing the potential role that adaptive approaches can play in increasing the efficiency of in situ visualization.
						<!-- abstract here end -->
					    </div></div><div id='stacks_out_1378_page0' class='stacks_out'><div id='stacks_in_1378_page0' class='stacks_in text_stack'>
						<!-- <a href="bibs/tlic.bib">[bib]</a> -->
						<!-- <a href="papers/tlic.pdf">[pdf]</a> -->
						<!-- <a href="videos/tlic_interaction.mp4">[video]</a> -->
						<br />
			    </div></div></div></div></div></div></div></div></div></div><div id='stacks_out_1032_page0' class='stacks_out'>				

			      <!-- end paper-->

			      


			    			    <!-- begin paper-->

			    <div id='stacks_out_1357_page0' class='stacks_out'><div id='stacks_in_1357_page0' class='stacks_in '><div id='stacks_out_1358_page0' class='stacks_out'><div id='stacks_in_1358_page0' class='stacks_in stack_stack'><div id='stacks_out_1360_page0' class='stacks_out'><div id='stacks_in_1360_page0' class='stacks_in stack_stack'><div id='stacks_out_1362_page0' class='stacks_out'><div id='stacks_in_1362_page0' class='stacks_in stack_stack'>

					    <!-- pics here begin -->
					    <div id='stacks_out_1364_page0' class='stacks_out'><div id='stacks_in_1364_page0' class='stacks_in image_stack'><div class='centered_image' ><img class='imageStyle' src='pics/contest19_poster.png' width='220' alt='Stacks Image 1365' /></div></div></div>
					    <!-- <div id='stacks_out_1364_page0' class='stacks_out'><div id='stacks_in_1364_page0' class='stacks_in image_stack'><div class='centered_image' ><img class='imageStyle' src='pics/gaze_kite.png' width='300' alt='Stacks Image 1365' /></div></div></div> -->

					    <!-- <div id='stacks_out_1366_page0' class='stacks_out'><div id='stacks_in_1366_page0' class='stacks_in image_stack'><div class='centered_image' ><img class='imageStyle' src='files/stacks_image_1367.png' width='300' height='150' alt='Stacks Image 1367' /></div></div></div> -->

					    <!-- <div id='stacks_out_1366_page0' class='stacks_out'><div id='stacks_in_1366_page0' class='stacks_in image_stack'><div class='centered_image' ><img class='imageStyle' src='pics/ev18/bottle.png' width='250' alt='Stacks Image 1367' /></div></div></div> -->
					    <!-- pics here end -->

				    </div></div>


					<div id='stacks_out_1368_page0' class='stacks_out'><div id='stacks_in_1368_page0' class='stacks_in stack_stack'><div id='stacks_out_1370_page0' class='stacks_out'><div id='stacks_in_1370_page0' class='stacks_in text_stack'><span id='stacks_in_1371_page0'>
						  <strong>Visual Analysis of Structure Formation in Cosmic Evolution</strong>
					    </span></div></div><div id='stacks_out_1372_page0' class='stacks_out'><div id='steacks_in_1372_page0' class='stacks_in text_stack'>
						<!-- authors here -->
						<em>K. Schatz, C. Müller, P. Gralka, M. Heinemann, A. Straub, C. Schulz, M. Braun, T. Rau, M. Becher, <br>P. Diehl, D. Marcello, J. Frank, T. Müller, S. Frey, G. Reina, D. Weiskopf, T. Ertl</em>
					      </div></div><div id='stacks_out_1374_page0' class='stacks_out'><div id='stacks_in_1374_page0' class='stacks_in text_stack'>
						   DOI: <a href="https://doi.org/10.1109/MCG.2020.3004613">10.1109/MCG.2020.3004613</a><br />
						  <a href="https://www.computer.org/csdl/magazine/cg">IEEE Computer Graphics and Applications</a><br/>


						<a href="https://press3.mcs.anl.gov/2019-scivis-contest">SciVis Contest 2019</a> <strong> | winner</strong>
					    </div></div><div id='stacks_out_1376_page0' class='stacks_out'><div id='stacks_in_1376_page0' class='stacks_in text_stack'>
						<!-- abstract here begin -->
						The IEEE SciVis 2019 Contest targets the visual analysis of structure formation in the cosmic evolution of the universe from when the universe was five million years old up to now. In our submission, we analyze high-dimensional data to get an overview, then investigate the impact of Active Galactic Nuclei (AGNs) using various visualization techniques, for instance, an adapted filament filtering method for detailed analysis and particle flow in the vicinity of filaments. Based on feedback from domain scientists on these initial visualizations, we also analyzed X-ray emissions and star formation areas. The conversion of star-forming gas to stars and the resulting increasing molecular weight of the particles could be observed.
						<!-- abstract here end -->
					    </div></div><div id='stacks_out_1378_page0' class='stacks_out'><div id='stacks_in_1378_page0' class='stacks_in text_stack'>
						<!-- <a href="papers/foveated_ev19.bib">[bib]</a> -->
						<!-- <a href="papers/local_prediction_models.pdf">[pdf]</a> -->
						<a href="https://youtu.be/ykn3ewqWUcw">[video]</a>
						<!-- <a href="papers/foveated_ev19.mp4">[mp4]</a> -->
						<br />
			    </div></div></div></div></div></div></div></div></div></div><div id='stacks_out_1032_page0' class='stacks_out'>				

			      <!-- end paper-->

			      			    <!-- begin paper-->

			    <!-- Hermann, S., Schneider, M., Flemisch, B., Frey, S., Iglezakis, D., Ruf, M., Schembera, B., Seeland, A. und Steeb, H. 2020. Datenmanagement im SFB 1313. Bausteine Forschungsdatenmanagement. 1 (Apr. 2020), 28-38. DOI:https://doi.org/10.17192/bfdm.2020.1.8085. -->
			    
			    <div id='stacks_out_1357_page0' class='stacks_out'><div id='stacks_in_1357_page0' class='stacks_in '><div id='stacks_out_1358_page0' class='stacks_out'><div id='stacks_in_1358_page0' class='stacks_in stack_stack'><div id='stacks_out_1360_page0' class='stacks_out'><div id='stacks_in_1360_page0' class='stacks_in stack_stack'><div id='stacks_out_1362_page0' class='stacks_out'><div id='stacks_in_1362_page0' class='stacks_in stack_stack'>

					    <!-- pics here begin -->
					    <div id='stacks_out_1364_page0' class='stacks_out'><div id='stacks_in_1364_page0' class='stacks_in image_stack'><div class='centered_image' ><img class='imageStyle' src='pics/forschungsdaten_sfb1313.png' width='220' alt='Stacks Image 1365' /></div></div></div>
					    <!-- <div id='stacks_out_1364_page0' class='stacks_out'><div id='stacks_in_1364_page0' class='stacks_in image_stack'><div class='centered_image' ><img class='imageStyle' src='pics/gaze_kite.png' width='300' alt='Stacks Image 1365' /></div></div></div> -->

					    <!-- <div id='stacks_out_1366_page0' class='stacks_out'><div id='stacks_in_1366_page0' class='stacks_in image_stack'><div class='centered_image' ><img class='imageStyle' src='files/stacks_image_1367.png' width='300' height='150' alt='Stacks Image 1367' /></div></div></div> -->

					    <!-- <div id='stacks_out_1366_page0' class='stacks_out'><div id='stacks_in_1366_page0' class='stacks_in image_stack'><div class='centered_image' ><img class='imageStyle' src='pics/ev18/bottle.png' width='250' alt='Stacks Image 1367' /></div></div></div> -->
					    <!-- pics here end -->

				    </div></div>


					<div id='stacks_out_1368_page0' class='stacks_out'><div id='stacks_in_1368_page0' class='stacks_in stack_stack'><div id='stacks_out_1370_page0' class='stacks_out'><div id='stacks_in_1370_page0' class='stacks_in text_stack'><span id='stacks_in_1371_page0'>
						  <strong>Datenmanagement im SFB 1313</strong>
					    </span></div></div><div id='stacks_out_1372_page0' class='stacks_out'><div id='steacks_in_1372_page0' class='stacks_in text_stack'>
						<!-- authors here -->
						<em>S. Hermann, M. Schneider, B. Flemisch, S. Frey, D. Iglezakis, M. Ruf, B. Schembera, A. Seeland, H. Steeb</em>
					      </div></div><div id='stacks_out_1374_page0' class='stacks_out'><div id='stacks_in_1374_page0' class='stacks_in text_stack'>
						   DOI: <a href="https://doi.org/10.17192/bfdm.2020.1.8085">10.17192/bfdm.2020.1.8085</a><br />
						  <a href="https://bausteine-fdm.de">Bausteine Forschungsdatenmanagement</a><br/>
					    </div></div><div id='stacks_out_1376_page0' class='stacks_out'><div id='stacks_in_1376_page0' class='stacks_in text_stack'>
						<!-- abstract here begin -->
						Dieser Artikel gibt einen Überblick über das Forschungsdatenmanagement im SFB 1313. Ein wesentliches Merkmal der geplanten Forschungstätigkeit im SFB ist die Verknüpfung von physikalischen und mathematischen Modellen und den daraus resultierenden Rechenmodellen mit hochaufgelösten Experimenten. Eine solche Verknüpfung stellt diverse Anforderungen an das Forschungsdatenmanagement. Diese Anforderungen sowie die damit einhergehenden Herausforderungen werden in diesem Artikel detailliert beschrieben. In diesem Zusammenhang wird das Datenrepositorium DaRUS vorgestellt, welches die Verwaltung und Beschreibung der im SFB anfallenden Daten ermöglicht. Zusätzlich wird das entwickelte Metadatenschema vorgestellt und auf die geplante automatisierte Metadatenerfassung eingegangen.
						<!-- Abstract here end -->
					    </div></div><div id='stacks_out_1378_page0' class='stacks_out'><div id='stacks_in_1378_page0' class='stacks_in text_stack'>
						<a href="papers/forschungsdaten_sfb1313.pdf">[pdf]</a>
						<br />
			    </div></div></div></div></div></div></div></div></div></div><div id='stacks_out_1032_page0' class='stacks_out'>

			      <!-- http://www.vis.uni-stuttgart.de/~freysn/ -->

			      <!-- end paper-->


			    <!-- header year-->
			    <div id='stacks_out_9_page0' class='stacks_out'><div id='stacks_in_9_page0' class='stacks_in text_stack'><span id='stacks_in_10_page0'>2019</span></div></div>




			    <!-- begin paper-->

			    <div id='stacks_out_1357_page0' class='stacks_out'><div id='stacks_in_1357_page0' class='stacks_in '><div id='stacks_out_1358_page0' class='stacks_out'><div id='stacks_in_1358_page0' class='stacks_in stack_stack'><div id='stacks_out_1360_page0' class='stacks_out'><div id='stacks_in_1360_page0' class='stacks_in stack_stack'><div id='stacks_out_1362_page0' class='stacks_out'><div id='stacks_in_1362_page0' class='stacks_in stack_stack'>

					    <!-- pics here begin -->
					    <div id='stacks_out_1364_page0' class='stacks_out'><div id='stacks_in_1364_page0' class='stacks_in image_stack'><div class='centered_image' ><img class='imageStyle' src='pics/ensemble_analysis.png' width='220' alt='Stacks Image 1365' /></div></div></div>
					    <!-- <div id='stacks_out_1364_page0' class='stacks_out'><div id='stacks_in_1364_page0' class='stacks_in image_stack'><div class='centered_image' ><img class='imageStyle' src='pics/gaze_kite.png' width='300' alt='Stacks Image 1365' /></div></div></div> -->

					    <!-- <div id='stacks_out_1366_page0' class='stacks_out'><div id='stacks_in_1366_page0' class='stacks_in image_stack'><div class='centered_image' ><img class='imageStyle' src='files/stacks_image_1367.png' width='300' height='150' alt='Stacks Image 1367' /></div></div></div> -->

					    <!-- <div id='stacks_out_1366_page0' class='stacks_out'><div id='stacks_in_1366_page0' class='stacks_in image_stack'><div class='centered_image' ><img class='imageStyle' src='pics/ev18/bottle.png' width='250' alt='Stacks Image 1367' /></div></div></div> -->
					    <!-- pics here end -->

				    </div></div>


					<div id='stacks_out_1368_page0' class='stacks_out'><div id='stacks_in_1368_page0' class='stacks_in stack_stack'><div id='stacks_out_1370_page0' class='stacks_out'><div id='stacks_in_1370_page0' class='stacks_in text_stack'><span id='stacks_in_1371_page0'>
						  <strong>Local Prediction Models for Spatiotemporal Volume Visualization</strong>
					    </span></div></div><div id='stacks_out_1372_page0' class='stacks_out'><div id='steacks_in_1372_page0' class='stacks_in text_stack'>
						<!-- authors here -->
						<em>G. Tkachev, S. Frey, T. Ertl</em>
					    </div></div><div id='stacks_out_1374_page0' class='stacks_out'><div id='stacks_in_1374_page0' class='stacks_in text_stack'>
						<!-- <a href="https://vis.lbl.gov/events/ISAV2019">ISAV 2019</a> -->
					    </div></div><div id='stacks_out_1376_page0' class='stacks_out'><div id='stacks_in_1376_page0' class='stacks_in text_stack'>
						<!-- abstract here begin -->
						We present a machine learning-based approach for detecting and visualizing complex behavior in spatiotemporal volumes. For this, we train models to predict future data values at a given position based on the past values in its neighborhood, capturing common temporal behavior in the data. We then evaluate the model’s prediction on the same data. High prediction error means that the local behavior was too complex, unique or uncertain to be accurately captured during training, indicating spatiotemporal regions with interesting behavior. By training several models of varying capacity, we are able to detect spatiotemporal regions of various complexities. We aggregate the obtained prediction errors into a time series or spatial volumes and visualize them together to highlight regions of unpredictable behavior and how they differ between the models. We demonstrate two further volumetric applications: adaptive timestep selection and analysis of ensemble dissimilarity. We apply our technique to datasets from multiple application domains and demonstrate that we are able to produce meaningful results while making minimal assumptions about the underlying data.
						<!-- abstract here end -->
					    </div></div><div id='stacks_out_1378_page0' class='stacks_out'><div id='stacks_in_1378_page0' class='stacks_in text_stack'>
						<!-- <a href="papers/foveated_ev19.bib">[bib]</a> -->
						<a href="papers/local_prediction_models.pdf">[pdf]</a>
						<!-- <a href="papers/foveated_ev19.mp4">[mp4]</a> -->
						<br />
			    </div></div></div></div></div></div></div></div></div></div><div id='stacks_out_1032_page0' class='stacks_out'>

			      <!-- http://www.vis.uni-stuttgart.de/~freysn/ -->

			      <!-- end paper-->


			    <!-- begin paper-->

			    <div id='stacks_out_1357_page0' class='stacks_out'><div id='stacks_in_1357_page0' class='stacks_in '><div id='stacks_out_1358_page0' class='stacks_out'><div id='stacks_in_1358_page0' class='stacks_in stack_stack'><div id='stacks_out_1360_page0' class='stacks_out'><div id='stacks_in_1360_page0' class='stacks_in stack_stack'><div id='stacks_out_1362_page0' class='stacks_out'><div id='stacks_in_1362_page0' class='stacks_in stack_stack'>

					    <!-- pics here begin -->
					    <div id='stacks_out_1364_page0' class='stacks_out'><div id='stacks_in_1364_page0' class='stacks_in image_stack'><div class='centered_image' ><img class='imageStyle' src='pics/insitu_distribution.png' width='155' alt='Stacks Image 1365' /></div></div></div>
					    <!-- <div id='stacks_out_1364_page0' class='stacks_out'><div id='stacks_in_1364_page0' class='stacks_in image_stack'><div class='centered_image' ><img class='imageStyle' src='pics/gaze_kite.png' width='300' alt='Stacks Image 1365' /></div></div></div> -->

					    <!-- <div id='stacks_out_1366_page0' class='stacks_out'><div id='stacks_in_1366_page0' class='stacks_in image_stack'><div class='centered_image' ><img class='imageStyle' src='files/stacks_image_1367.png' width='300' height='150' alt='Stacks Image 1367' /></div></div></div> -->

					    <!-- <div id='stacks_out_1366_page0' class='stacks_out'><div id='stacks_in_1366_page0' class='stacks_in image_stack'><div class='centered_image' ><img class='imageStyle' src='pics/ev18/bottle.png' width='250' alt='Stacks Image 1367' /></div></div></div> -->
					    <!-- pics here end -->

				    </div></div>


					<div id='stacks_out_1368_page0' class='stacks_out'><div id='stacks_in_1368_page0' class='stacks_in stack_stack'><div id='stacks_out_1370_page0' class='stacks_out'><div id='stacks_in_1370_page0' class='stacks_in text_stack'><span id='stacks_in_1371_page0'>
						  <strong>The Impact of Work Distribution on In Situ Visualization: A Case Study</strong>
					    </span></div></div><div id='stacks_out_1372_page0' class='stacks_out'><div id='steacks_in_1372_page0' class='stacks_in text_stack'>
						<!-- authors here -->
						<em>T. Rau, P. Gralka, O. Fernandes, G. Reina, S. Frey, T. Ertl</em>
					    </div></div><div id='stacks_out_1374_page0' class='stacks_out'><div id='stacks_in_1374_page0' class='stacks_in text_stack'>
						<a href="https://vis.lbl.gov/events/ISAV2019">ISAV 2019</a><strong> | honorable mention</strong>
					    </div></div><div id='stacks_out_1376_page0' class='stacks_out'><div id='stacks_in_1376_page0' class='stacks_in text_stack'>
						<!-- abstract here begin -->
						Large-scale computer simulations generate data at rates that necessitate visual analysis tools to run in situ. The distribution of work on and across nodes of a supercomputer is crucial to utilize compute resources as efficiently as possible. In this paper, we study two work distribution problems in the context of in situ visualization and jointly assess the performance impact of different variants. First, especially for simulations involving heterogeneous loads across their domain, dynamic load balancing can significantly reduce simulation run times. However, the adjustment of the domain partitioning associated with this also has a direct impact on visualization performance. The exact impact of this is side effect is largely unclear a priori as generally different criteria are used for balancing simulation and visualization load. Second, on node level, the adequate allocation of threads to simulation or visualization tasks minimizes the performance drain of the simulation while also enabling timely visualization results. In our case study, we jointly study both work distribution aspects with the visualization framework MegaMol coupled in situ on node level to the molecular dynamics simulation ls1 Mardyn on Stampede2 at TACC.
						<!-- abstract here end -->
					    </div></div><div id='stacks_out_1378_page0' class='stacks_out'><div id='stacks_in_1378_page0' class='stacks_in text_stack'>
						<!-- <a href="papers/foveated_ev19.bib">[bib]</a> -->
						<!-- <a href="papers/foveated_ev19.pdf">[pdf]</a> -->
						<!-- <a href="papers/foveated_ev19.mp4">[mp4]</a> -->
						<br />
			    </div></div></div></div></div></div></div></div></div></div><div id='stacks_out_1032_page0' class='stacks_out'>

			      <!-- http://www.vis.uni-stuttgart.de/~freysn/ -->

			      <!-- end paper-->

			      <!-- begin paper-->

			    <div id='stacks_out_1357_page0' class='stacks_out'><div id='stacks_in_1357_page0' class='stacks_in '><div id='stacks_out_1358_page0' class='stacks_out'><div id='stacks_in_1358_page0' class='stacks_in stack_stack'><div id='stacks_out_1360_page0' class='stacks_out'><div id='stacks_in_1360_page0' class='stacks_in stack_stack'><div id='stacks_out_1362_page0' class='stacks_out'><div id='stacks_in_1362_page0' class='stacks_in stack_stack'>

					    <!-- pics here begin -->
					    <div id='stacks_out_1364_page0' class='stacks_out'><div id='stacks_in_1364_page0' class='stacks_in image_stack'><div class='centered_image' ><img class='imageStyle' src='pics/region_transitions.png' width='200' alt='Stacks Image 1365' /></div></div></div>
					    <!-- <div id='stacks_out_1364_page0' class='stacks_out'><div id='stacks_in_1364_page0' class='stacks_in image_stack'><div class='centered_image' ><img class='imageStyle' src='pics/gaze_kite.png' width='300' alt='Stacks Image 1365' /></div></div></div> -->

					    <!-- <div id='stacks_out_1366_page0' class='stacks_out'><div id='stacks_in_1366_page0' class='stacks_in image_stack'><div class='centered_image' ><img class='imageStyle' src='files/stacks_image_1367.png' width='300' height='150' alt='Stacks Image 1367' /></div></div></div> -->

					    <!-- <div id='stacks_out_1366_page0' class='stacks_out'><div id='stacks_in_1366_page0' class='stacks_in image_stack'><div class='centered_image' ><img class='imageStyle' src='pics/ev18/bottle.png' width='250' alt='Stacks Image 1367' /></div></div></div> -->
					    <!-- pics here end -->

				    </div></div>


					<div id='stacks_out_1368_page0' class='stacks_out'><div id='stacks_in_1368_page0' class='stacks_in stack_stack'><div id='stacks_out_1370_page0' class='stacks_out'><div id='stacks_in_1370_page0' class='stacks_in text_stack'><span id='stacks_in_1371_page0'>
						  <strong>Visual Representation of Region Transitions in Multi-dimensional Parameter Spaces</strong>
					    </span></div></div><div id='stacks_out_1372_page0' class='stacks_out'><div id='steacks_in_1372_page0' class='stacks_in text_stack'>
						<!-- authors here -->
						<em>O. Fernandes, S. Frey, G. Reina, T. Ertl</em>
					    </div></div><div id='stacks_out_1374_page0' class='stacks_out'><div id='stacks_in_1374_page0' class='stacks_in text_stack'>
						<a href="http://stag2019.crs4.it/">STAG 2019</a>
					    </div></div><div id='stacks_out_1376_page0' class='stacks_out'><div id='stacks_in_1376_page0' class='stacks_in text_stack'>
						<!-- abstract here begin -->
						We propose a novel visual representation of transitions between homogeneous regions in multi-dimensional parameter space.
While our approach is generally applicable for the analysis of arbitrary continuous parameter spaces, we particularly focus on scientific applications, like physical variables in simulation ensembles.
To generate our representation, we use unsupervised learning to cluster the ensemble members according to their mutual similarity.
In doing this, clusters are sorted such that similar clusters are located next to each other.
We then further partition the clusters into connected regions with respect to their location in parameter space.
In the visualization, the resulting regions are represented as glyphs in a matrix, indicating parameter changes which induce a transition to another region.
To unambiguously associate a change of data characteristics to a single parameter, we specifically isolate changes by dimension.
With this, our representation provides an intuitive visualization of the parameter transitions that influence the outcome of the underlying simulation or measurement.
We demonstrate the generality and utility of our approach on diverse types of data, namely simulations from the field of computational fluid dynamics and thermodynamics, as well as an ensemble of raycasting performance data.
						<!-- abstract here end -->
					    </div></div><div id='stacks_out_1378_page0' class='stacks_out'><div id='stacks_in_1378_page0' class='stacks_in text_stack'>
						<!-- <a href="papers/foveated_ev19.bib">[bib]</a> -->
						<!-- <a href="papers/foveated_ev19.pdf">[pdf]</a> -->
						<!-- <a href="papers/foveated_ev19.mp4">[mp4]</a> -->
						<br />
			    </div></div></div></div></div></div></div></div></div></div><div id='stacks_out_1032_page0' class='stacks_out'>

			      <!-- http://www.vis.uni-stuttgart.de/~freysn/ -->

			      <!-- end paper-->

			    <!-- begin paper-->

			    <div id='stacks_out_1357_page0' class='stacks_out'><div id='stacks_in_1357_page0' class='stacks_in '><div id='stacks_out_1358_page0' class='stacks_out'><div id='stacks_in_1358_page0' class='stacks_in stack_stack'><div id='stacks_out_1360_page0' class='stacks_out'><div id='stacks_in_1360_page0' class='stacks_in stack_stack'><div id='stacks_out_1362_page0' class='stacks_out'><div id='stacks_in_1362_page0' class='stacks_in stack_stack'>

					    <!-- pics here begin -->
					    <div id='stacks_out_1364_page0' class='stacks_out'><div id='stacks_in_1364_page0' class='stacks_in image_stack'><div class='centered_image' ><img class='imageStyle' src='pics/foveated_lambda2.png' width='300' alt='Stacks Image 1365' /></div></div></div>
					    <!-- <div id='stacks_out_1364_page0' class='stacks_out'><div id='stacks_in_1364_page0' class='stacks_in image_stack'><div class='centered_image' ><img class='imageStyle' src='pics/gaze_kite.png' width='300' alt='Stacks Image 1365' /></div></div></div> -->

					    <!-- <div id='stacks_out_1366_page0' class='stacks_out'><div id='stacks_in_1366_page0' class='stacks_in image_stack'><div class='centered_image' ><img class='imageStyle' src='files/stacks_image_1367.png' width='300' height='150' alt='Stacks Image 1367' /></div></div></div> -->

					    <!-- <div id='stacks_out_1366_page0' class='stacks_out'><div id='stacks_in_1366_page0' class='stacks_in image_stack'><div class='centered_image' ><img class='imageStyle' src='pics/ev18/bottle.png' width='250' alt='Stacks Image 1367' /></div></div></div> -->
					    <!-- pics here end -->

				    </div></div>


					<div id='stacks_out_1368_page0' class='stacks_out'><div id='stacks_in_1368_page0' class='stacks_in stack_stack'><div id='stacks_out_1370_page0' class='stacks_out'><div id='stacks_in_1370_page0' class='stacks_in text_stack'><span id='stacks_in_1371_page0'>
						  <strong>Voronoi-Based Foveated Volume Rendering</strong>
					    </span></div></div><div id='stacks_out_1372_page0' class='stacks_out'><div id='steacks_in_1372_page0' class='stacks_in text_stack'>
						<!-- authors here -->
						<em>V. Bruder, C. Schulz, R. Bauer, S. Frey, D. Weiskopf, T. Ertl</em>
					    </div></div><div id='stacks_out_1374_page0' class='stacks_out'><div id='stacks_in_1374_page0' class='stacks_in text_stack'>
						<a href="http://eurovis2019.org/">EuroVis 2019</a> <strong>| best short paper</strong>
					    </div></div><div id='stacks_out_1376_page0' class='stacks_out'><div id='stacks_in_1376_page0' class='stacks_in text_stack'>
						<!-- abstract here begin -->
						Foveal vision is located in the center of the field of view with a rich impression of detail and color, whereas peripheral vision occurs on the side with more fuzzy and colorless perception. This visual acuity fall-off can be used to achieve higher frame rates by adapting rendering quality to the human visual system. Volume raycasting has unique characteristics, preventing a direct transfer of many traditional foveated rendering techniques. We present an approach that utilizes the visual acuity fall-off to accelerate volume rendering based on Linde-Buzo-Gray sampling and natural neighbor interpolation. First, we measure gaze using a stationary 1200Hz eye-tracking system. Then, we adapt our sampling and reconstruction strategy to that gaze. Finally, we apply a temporal smoothing filter to attenuate undersampling artifacts since peripheral vision is particularly sensitive to contrast changes and movement. Our approach substantially improves rendering performance with barely perceptible changes in visual quality.
						<!-- abstract here end -->
					    </div></div><div id='stacks_out_1378_page0' class='stacks_out'><div id='stacks_in_1378_page0' class='stacks_in text_stack'>
						<a href="papers/foveated_ev19.bib">[bib]</a>
						<a href="papers/foveated_ev19.pdf">[pdf]</a>
						<a href="papers/foveated_ev19.mp4">[mp4]</a>
						<a href="https://github.com/vbruder/FoveatedVolumeRendering">[code]</a>
						<br />
			    </div></div></div></div></div></div></div></div></div></div><div id='stacks_out_1032_page0' class='stacks_out'>

			      <!-- http://www.vis.uni-stuttgart.de/~freysn/ -->

			      <!-- end paper-->

			    <!-- begin paper-->

			    <div id='stacks_out_1357_page0' class='stacks_out'><div id='stacks_in_1357_page0' class='stacks_in '><div id='stacks_out_1358_page0' class='stacks_out'><div id='stacks_in_1358_page0' class='stacks_in stack_stack'><div id='stacks_out_1360_page0' class='stacks_out'><div id='stacks_in_1360_page0' class='stacks_in stack_stack'><div id='stacks_out_1362_page0' class='stacks_out'><div id='stacks_in_1362_page0' class='stacks_in stack_stack'>

					    <!-- pics here begin -->
					    <div id='stacks_out_1364_page0' class='stacks_out'><div id='stacks_in_1364_page0' class='stacks_in image_stack'><div class='centered_image' ><img class='imageStyle' src='pics/gaze_app.png' width='300' alt='Stacks Image 1365' /></div></div></div>
					    <div id='stacks_out_1364_page0' class='stacks_out'><div id='stacks_in_1364_page0' class='stacks_in image_stack'><div class='centered_image' ><img class='imageStyle' src='pics/gaze_kite.png' width='300' alt='Stacks Image 1365' /></div></div></div>

					    <!-- <div id='stacks_out_1366_page0' class='stacks_out'><div id='stacks_in_1366_page0' class='stacks_in image_stack'><div class='centered_image' ><img class='imageStyle' src='files/stacks_image_1367.png' width='300' height='150' alt='Stacks Image 1367' /></div></div></div> -->

					    <!-- <div id='stacks_out_1366_page0' class='stacks_out'><div id='stacks_in_1366_page0' class='stacks_in image_stack'><div class='centered_image' ><img class='imageStyle' src='pics/ev18/bottle.png' width='250' alt='Stacks Image 1367' /></div></div></div> -->
					    <!-- pics here end -->

				    </div></div>


					<div id='stacks_out_1368_page0' class='stacks_out'><div id='stacks_in_1368_page0' class='stacks_in stack_stack'><div id='stacks_out_1370_page0' class='stacks_out'><div id='stacks_in_1370_page0' class='stacks_in text_stack'><span id='stacks_in_1371_page0'>
						  <strong>Space-Time Volume Visualization of Gaze and Stimulus</strong>
					    </span></div></div><div id='stacks_out_1372_page0' class='stacks_out'><div id='steacks_in_1372_page0' class='stacks_in text_stack'>
						<!-- authors here -->
						<em>V. Bruder, K. Kurzhals, S. Frey, D. Weiskopf, T. Ertl</em>
					    </div></div><div id='stacks_out_1374_page0' class='stacks_out'><div id='stacks_in_1374_page0' class='stacks_in text_stack'>
						<a href="http://etra.acm.org/2019/">ETRA 2019</a>
					    </div></div><div id='stacks_out_1376_page0' class='stacks_out'><div id='stacks_in_1376_page0' class='stacks_in text_stack'>
						<!-- abstract here begin -->
						We present an approach for the spatio-temporal analysis of gaze data from multiple participants in the context of a video stimulus. For such data, an overview of the recorded patterns is important to identify common viewing behavior (such as attentional synchrony) and outliers.  We adopt the approach of a space-time cube visualization, which extends the spatial dimensions of the stimulus by time as the third dimension.  Previous work mainly handled eye-tracking data in the space-time cube as point cloud, providing no information about the stimulus context.  This paper presents a novel visualization technique that combines gaze data, a dynamic stimulus, and optical flow with volume rendering to derive an overview of the data with contextual information. With specifically designed transfer functions, we emphasize different data aspects, making the visualization suitable for explorative analysis and for illustrative support of statistical findings alike.
						<!-- abstract here end -->
					    </div></div><div id='stacks_out_1378_page0' class='stacks_out'><div id='stacks_in_1378_page0' class='stacks_in text_stack'>
						<a href="papers/gaze_etra19.bib">[bib]</a>
						<a href="papers/gaze_etra19.pdf">[pdf]</a>
						<!-- <a href="papers/contours_ev18.mp4">[mp4]</a> -->
						<br />
			    </div></div></div></div></div></div></div></div></div></div><div id='stacks_out_1032_page0' class='stacks_out'>

			      <!-- http://www.vis.uni-stuttgart.de/~freysn/ -->

			      <!-- end paper-->

			    			    <!-- begin paper-->

			    <div id='stacks_out_1357_page0' class='stacks_out'><div id='stacks_in_1357_page0' class='stacks_in '><div id='stacks_out_1358_page0' class='stacks_out'><div id='stacks_in_1358_page0' class='stacks_in stack_stack'><div id='stacks_out_1360_page0' class='stacks_out'><div id='stacks_in_1360_page0' class='stacks_in stack_stack'><div id='stacks_out_1362_page0' class='stacks_out'><div id='stacks_in_1362_page0' class='stacks_in stack_stack'>

					    <div id='stacks_out_1364_page0' class='stacks_out'><div id='stacks_in_1364_page0' class='stacks_in image_stack'><div class='centered_image' ><img class='imageStyle' src='pics/trrojan.png' width='300' alt='Stacks Image 1365' /></div></div></div>

					    <!-- <div id='stacks_out_1366_page0' class='stacks_out'><div id='stacks_in_1366_page0' class='stacks_in image_stack'><div class='centered_image' ><img class='imageStyle' src='files/stacks_image_1367.png' width='300' height='150' alt='Stacks Image 1367' /></div></div></div> -->

					    <!-- <div id='stacks_out_1366_page0' class='stacks_out'><div id='stacks_in_1366_page0' class='stacks_in image_stack'><div class='centered_image' ><img class='imageStyle' src='pics/ev18/bottle.png' width='250' alt='Stacks Image 1367' /></div></div></div> -->


				    </div></div>


					<div id='stacks_out_1368_page0' class='stacks_out'><div id='stacks_in_1368_page0' class='stacks_in stack_stack'><div id='stacks_out_1370_page0' class='stacks_out'><div id='stacks_in_1370_page0' class='stacks_in text_stack'><span id='stacks_in_1371_page0'><strong>On Evaluating Runtime Performance of Interactive Visualizations</strong></span></div></div><div id='stacks_out_1372_page0' class='stacks_out'><div id='steacks_in_1372_page0' class='stacks_in text_stack'><em>V. Bruder, C. M&uuml;ller, S. Frey, T. Ertl</em></div></div><div id='stacks_out_1374_page0' class='stacks_out'><div id='stacks_in_1374_page0' class='stacks_in text_stack'>
						<a href="https://www.computer.org/web/tvcg">TVCG (presented at VIS 2019)</a>
					    </div></div><div id='stacks_out_1376_page0' class='stacks_out'><div id='stacks_in_1376_page0' class='stacks_in text_stack'>
						<!-- abstract here begin -->
						As our field matures, evaluation of visualization techniques has extended from reporting runtime performance to studying user behavior. Consequently, many methodologies and best practices for user studies have evolved. While maintaining interactivity continues to be crucial for the exploration of large data sets, no similar methodological foundation for evaluating runtime performance has been developed. Our analysis of 50 recent visualization papers on new or improved techniques for rendering volumes or particles indicates that only a very limited set of parameters like different data sets, camera paths, viewport sizes, and GPUs are investigated, which make comparison with other techniques or generalization to other parameter ranges at least questionable. To derive a deeper understanding of qualitative runtime behavior and quantitative parameter dependencies, we developed a framework for the most exhaustive performance evaluation of volume and particle visualization techniques that we are aware of, including millions of measurements on ten different GPUs. This paper reports on our insights from statistical analysis of this data, discussing independent and linear parameter behavior and non-obvious effects. We give recommendations for best practices when evaluating runtime performance of scientific visualization applications, which can serve as a starting point for more elaborate models of performance quantification.
						<!-- abstract here end -->
					    </div></div><div id='stacks_out_1378_page0' class='stacks_out'><div id='stacks_in_1378_page0' class='stacks_in text_stack'>
						<a href="papers/performance_tvcg19.bib">[bib]</a>
						<a href="papers/performance_tvcg19.pdf">[pdf]</a>
						<!-- <a href="papers/contours_ev18.mp4">[mp4]</a> -->
						<a href="http://trrojan.visus.uni-stuttgart.de">[website]</a>
						<a href="https://github.com/UniStuttgart-VISUS/trrojan">[code]</a>
						<br />
			    </div></div></div></div></div></div></div></div></div></div><div id='stacks_out_1032_page0' class='stacks_out'>

			      <!-- http://www.vis.uni-stuttgart.de/~freysn/ -->

			      <!-- end paper-->

			    <!-- begin paper-->

			    <div id='stacks_out_1357_page0' class='stacks_out'><div id='stacks_in_1357_page0' class='stacks_in '><div id='stacks_out_1358_page0' class='stacks_out'><div id='stacks_in_1358_page0' class='stacks_in stack_stack'><div id='stacks_out_1360_page0' class='stacks_out'><div id='stacks_in_1360_page0' class='stacks_in stack_stack'><div id='stacks_out_1362_page0' class='stacks_out'><div id='stacks_in_1362_page0' class='stacks_in stack_stack'>

					    <!-- pics here begin -->
					    <div id='stacks_out_1364_page0' class='stacks_out'><div id='stacks_in_1364_page0' class='stacks_in image_stack'><div class='centered_image' ><img class='imageStyle' src='pics/fractureMech.png' width='170' alt='Stacks Image 1365' /></div></div></div>
					    <!-- <div id='stacks_out_1364_page0' class='stacks_out'><div id='stacks_in_1364_page0' class='stacks_in image_stack'><div class='centered_image' ><img class='imageStyle' src='pics/gaze_kite.png' width='300' alt='Stacks Image 1365' /></div></div></div> -->

					    <!-- <div id='stacks_out_1366_page0' class='stacks_out'><div id='stacks_in_1366_page0' class='stacks_in image_stack'><div class='centered_image' ><img class='imageStyle' src='files/stacks_image_1367.png' width='300' height='150' alt='Stacks Image 1367' /></div></div></div> -->

					    <!-- <div id='stacks_out_1366_page0' class='stacks_out'><div id='stacks_in_1366_page0' class='stacks_in image_stack'><div class='centered_image' ><img class='imageStyle' src='pics/ev18/bottle.png' width='250' alt='Stacks Image 1367' /></div></div></div> -->
					    <!-- pics here end -->

				    </div></div>


					<div id='stacks_out_1368_page0' class='stacks_out'><div id='stacks_in_1368_page0' class='stacks_in stack_stack'><div id='stacks_out_1370_page0' class='stacks_out'><div id='stacks_in_1370_page0' class='stacks_in text_stack'><span id='stacks_in_1371_page0'>
						  <strong>Hybrid image processing approach for autonomous crack area detection and tracking using local digital image correlation results applied to single-fiber interfacial debonding</strong>
					    </span></div></div><div id='stacks_out_1372_page0' class='stacks_out'><div id='steacks_in_1372_page0' class='stacks_in text_stack'>
						<!-- authors here -->
						<em>I. Tabiai, G. Tkachev, P. Diehl, S. Frey, T. Ertl, D. Therriault, M. Lévesque</em>
					    </div></div><div id='stacks_out_1374_page0' class='stacks_out'><div id='stacks_in_1374_page0' class='stacks_in text_stack'>
						<a href="https://www.elsevier.com/locate/engfracmech">Engineering in Fracture Mechanics</a>
					    </div></div><div id='stacks_out_1376_page0' class='stacks_out'><div id='stacks_in_1376_page0' class='stacks_in text_stack'>
						<!-- abstract here begin -->
						Local digital image correlation is a popular method for accurate full field displacement measurements. However, the technique struggles at autonomously tracking emerging and propagating cracks. We proposed a hybrid approach which utilizes image processing techniques in combination with local digital image correlation to autonomously monitor cracks in a mechanically loaded specimen. Our approach can extract and track crack surfaces and provide a volume-based visualization of the crack growth. This approach was applied to single-fiber composite experimental results with interfacial debonding from the literature. Results quantitatively show that strong interfacial fiber/matrix bonding leads to slower interfacial crack growth, delays interfacial crack growth in the matrix, requires higher loadings for crack growth and shows a specific crack path distinct from the one obtained for weak interfaces. The approach was also validated against a manual approach where a domain scientist extracts a crack using a polygon extraction tool. The method can be used on any local digital image correlation results involving damage observations.
						<!-- abstract here end -->
					    </div></div><div id='stacks_out_1378_page0' class='stacks_out'><div id='stacks_in_1378_page0' class='stacks_in text_stack'>
						<a href="papers/fractureMech.bib">[bib]</a>
						<!-- <a href="papers/contours_ev18.pdf">[pdf]</a> -->
						<!-- <a href="papers/contours_ev18.mp4">[mp4]</a> -->
						<br />
			    </div></div></div></div></div></div></div></div></div></div><div id='stacks_out_1032_page0' class='stacks_out'>

			      <!-- http://www.vis.uni-stuttgart.de/~freysn/ -->

			      <!-- end paper-->

			    <!-- header year-->
			    <div id='stacks_out_9_page0' class='stacks_out'><div id='stacks_in_9_page0' class='stacks_in text_stack'><span id='stacks_in_10_page0'>2018</span></div></div>


			    			    <!-- begin paper-->

			    <div id='stacks_out_1357_page0' class='stacks_out'><div id='stacks_in_1357_page0' class='stacks_in '><div id='stacks_out_1358_page0' class='stacks_out'><div id='stacks_in_1358_page0' class='stacks_in stack_stack'><div id='stacks_out_1360_page0' class='stacks_out'><div id='stacks_in_1360_page0' class='stacks_in stack_stack'><div id='stacks_out_1362_page0' class='stacks_out'><div id='stacks_in_1362_page0' class='stacks_in stack_stack'>

					    <div id='stacks_out_1364_page0' class='stacks_out'><div id='stacks_in_1364_page0' class='stacks_in image_stack'><div class='centered_image' ><img class='imageStyle' src='pics/adaption.png' width='280' alt='Stacks Image 1365' /></div></div></div>

					    <!-- <div id='stacks_out_1366_page0' class='stacks_out'><div id='stacks_in_1366_page0' class='stacks_in image_stack'><div class='centered_image' ><img class='imageStyle' src='files/stacks_image_1367.png' width='300' height='150' alt='Stacks Image 1367' /></div></div></div> -->

					    <!-- <div id='stacks_out_1366_page0' class='stacks_out'><div id='stacks_in_1366_page0' class='stacks_in image_stack'><div class='centered_image' ><img class='imageStyle' src='pics/ev18/bottle.png' width='250' alt='Stacks Image 1367' /></div></div></div> -->


				    </div></div>


					<div id='stacks_out_1368_page0' class='stacks_out'><div id='stacks_in_1368_page0' class='stacks_in stack_stack'><div id='stacks_out_1370_page0' class='stacks_out'><div id='stacks_in_1370_page0' class='stacks_in text_stack'><span id='stacks_in_1371_page0'><strong>Adaptive Encoder Settings for Interactive Remote Visualisation on High-Resolution Displays</strong></span></div></div><div id='stacks_out_1372_page0' class='stacks_out'><div id='steacks_in_1372_page0' class='stacks_in text_stack'><em>F. Frieß, M. Landwehr, V. Bruder, S. Frey, T. Ertl</em></div></div><div id='stacks_out_1374_page0' class='stacks_out'><div id='stacks_in_1374_page0' class='stacks_in text_stack'>
						<a href="http://http://ieeevis.org">LDAV 2018 (short paper)</a>
					    </div></div><div id='stacks_out_1376_page0' class='stacks_out'><div id='stacks_in_1376_page0' class='stacks_in text_stack'>
						<!-- abstract here begin -->
						We present an approach that dynamically adapts encoder settings for image tiles to yield the best possible quality for a given bandwidth. This reduces the overall size of the image while preserving details. Our application determines the encoding settings in two steps. In the first step, we predict the quality and size of the tiles for different encoding settings using a convolutional neural network. In the second step, we assign the optimal encoder setting to each tile, so that the overall size of the image is lower than a predetermined threshold. Commonly, for tiles that contain complicated structures, a high quality setting is used in order to prevent major information loss, while quality settings are lowered for others to keep the size below the threshold. We demonstrate that we can reduce the overall size of the image while preserving the details in areas of interest using the example of both particle and volume visualisation applications.
						<!-- abstract here end -->
					    </div></div><div id='stacks_out_1378_page0' class='stacks_out'><div id='stacks_in_1378_page0' class='stacks_in text_stack'>
						<!-- <a href="papers/contours_ev18.bib">[bib]</a> -->
						<!-- <a href="papers/contours_ev18.pdf">[pdf]</a> -->
						<!-- <a href="papers/contours_ev18.mp4">[mp4]</a> -->
						<br />
			    </div></div></div></div></div></div></div></div></div></div><div id='stacks_out_1032_page0' class='stacks_out'>

			      <!-- http://www.vis.uni-stuttgart.de/~freysn/ -->

			      <!-- end paper-->


			    <!-- begin paper-->

			    <div id='stacks_out_1357_page0' class='stacks_out'><div id='stacks_in_1357_page0' class='stacks_in '><div id='stacks_out_1358_page0' class='stacks_out'><div id='stacks_in_1358_page0' class='stacks_in stack_stack'><div id='stacks_out_1360_page0' class='stacks_out'><div id='stacks_in_1360_page0' class='stacks_in stack_stack'><div id='stacks_out_1362_page0' class='stacks_out'><div id='stacks_in_1362_page0' class='stacks_in stack_stack'>

					    <div id='stacks_out_1364_page0' class='stacks_out'><div id='stacks_in_1364_page0' class='stacks_in image_stack'><div class='centered_image' ><img class='imageStyle' src='pics/bubbles.png' width='300' alt='Stacks Image 1365' /></div></div></div>

					    <!-- <div id='stacks_out_1366_page0' class='stacks_out'><div id='stacks_in_1366_page0' class='stacks_in image_stack'><div class='centered_image' ><img class='imageStyle' src='files/stacks_image_1367.png' width='300' height='150' alt='Stacks Image 1367' /></div></div></div> -->

					    <!-- <div id='stacks_out_1366_page0' class='stacks_out'><div id='stacks_in_1366_page0' class='stacks_in image_stack'><div class='centered_image' ><img class='imageStyle' src='pics/ev18/bottle.png' width='250' alt='Stacks Image 1367' /></div></div></div> -->


				    </div></div>


					<div id='stacks_out_1368_page0' class='stacks_out'><div id='stacks_in_1368_page0' class='stacks_in stack_stack'><div id='stacks_out_1370_page0' class='stacks_out'><div id='stacks_in_1370_page0' class='stacks_in text_stack'><span id='stacks_in_1371_page0'><strong>Visualization of Bubble Formation in Porous Media</strong></span></div></div><div id='stacks_out_1372_page0' class='stacks_out'><div id='steacks_in_1372_page0' class='stacks_in text_stack'><em>H. Zhang, S. Frey, H. Steeb, D. Uribe, T. Ertl, W. Wang</em></div></div><div id='stacks_out_1374_page0' class='stacks_out'><div id='stacks_in_1374_page0' class='stacks_in text_stack'>
						<a href="http://http://ieeevis.org">VIS 2018</a>
					    </div></div><div id='stacks_out_1376_page0' class='stacks_out'><div id='stacks_in_1376_page0' class='stacks_in text_stack'>
						We present a visualization approach for the analysis of CO2 bubble-induced attenuation in porous rock formations. As a basis for this, we introduce customized techniques to extract CO2 bubbles and their surrounding porous structure from X-ray computed tomography data (XCT) measurements. To understand how the structure of porous media influences the occurrence and the shape of formed bubbles, we automatically classify and relate them in terms of morphology and geometric features, and further directly support searching for promising porous structures. To allow for the meaningful direct visual comparison of bubbles and their structures, we propose a customized registration technique considering the bubble shape as well as its points of contact with the porous media surface.	With our quantitative extraction of geometric bubble features, we further support the analysis as well as the creation of a physical model. We demonstrate that our approach was successfully used to answer several research questions in the domain, and discuss its high practical relevance to identify critical seismic characteristics of fluid-saturated rock that govern its capability to store CO2.
					    </div></div><div id='stacks_out_1378_page0' class='stacks_out'><div id='stacks_in_1378_page0' class='stacks_in text_stack'>
						<!-- <a href="papers/contours_ev18.bib">[bib]</a> -->
						<!-- <a href="papers/contours_ev18.pdf">[pdf]</a> -->
						<!-- <a href="papers/contours_ev18.mp4">[mp4]</a> -->
						<br />
			    </div></div></div></div></div></div></div></div></div></div><div id='stacks_out_1032_page0' class='stacks_out'>

			      <!-- http://www.vis.uni-stuttgart.de/~freysn/ -->

			      <!-- end paper-->

			    			    <!-- begin paper-->

			    <div id='stacks_out_1357_page0' class='stacks_out'><div id='stacks_in_1357_page0' class='stacks_in '><div id='stacks_out_1358_page0' class='stacks_out'><div id='stacks_in_1358_page0' class='stacks_in stack_stack'><div id='stacks_out_1360_page0' class='stacks_out'><div id='stacks_in_1360_page0' class='stacks_in stack_stack'><div id='stacks_out_1362_page0' class='stacks_out'><div id='stacks_in_1362_page0' class='stacks_in stack_stack'>

					    <div id='stacks_out_1364_page0' class='stacks_out'><div id='stacks_in_1364_page0' class='stacks_in image_stack'><div class='centered_image' ><img class='imageStyle' src='pics/ev18/droplet.png' width='250' alt='Stacks Image 1365' /></div></div></div>

					    <!-- <div id='stacks_out_1366_page0' class='stacks_out'><div id='stacks_in_1366_page0' class='stacks_in image_stack'><div class='centered_image' ><img class='imageStyle' src='files/stacks_image_1367.png' width='300' height='150' alt='Stacks Image 1367' /></div></div></div> -->

					    <div id='stacks_out_1366_page0' class='stacks_out'><div id='stacks_in_1366_page0' class='stacks_in image_stack'><div class='centered_image' ><img class='imageStyle' src='pics/ev18/bottle.png' width='250' alt='Stacks Image 1367' /></div></div></div>


				    </div></div>


					<div id='stacks_out_1368_page0' class='stacks_out'><div id='stacks_in_1368_page0' class='stacks_in stack_stack'><div id='stacks_out_1370_page0' class='stacks_out'><div id='stacks_in_1370_page0' class='stacks_in text_stack'><span id='stacks_in_1371_page0'><strong>Spatio-Temporal Contours from Deep Volume Raycasting</strong></span></div></div><div id='stacks_out_1372_page0' class='stacks_out'><div id='stacks_in_1372_page0' class='stacks_in text_stack'><em>S. Frey</em></div></div><div id='stacks_out_1374_page0' class='stacks_out'><div id='stacks_in_1374_page0' class='stacks_in text_stack'>
						<a href="http://http://www.eurovis2018.org">EuroVIS 2018</a>
					    </div></div><div id='stacks_out_1376_page0' class='stacks_out'><div id='stacks_in_1376_page0' class='stacks_in text_stack'>
						We visualize contours for spatio-temporal processes to indicate where and when non-continuous changes occur or spatial bounds are encountered. All time steps are comprised densely in one visualization, with contours allowing to efficiently analyze processes in the data even in case of spatial or temporal overlap. Contours are determined on the basis of deep raycasting that collects samples across time and depth along each ray. For each sample along a ray, its closest neighbors from adjacent rays are identified, considering time, depth, and value in the process. Large distances are represented as contours in image space, using color to indicate temporal occurrence. This contour representation can easily be combined with volume rendering-based techniques, providing both full spatial detail for individual time steps and an outline of the whole time series in one view. Our view-dependent technique supports efficient progressive computation, and requires no prior assumptions regarding the shape or nature of processes in the data. We discuss and demonstrate the performance and utility of our approach via a variety of data sets, comparison and combination with an alternative technique, and feedback by a domain scientist.
					    </div></div><div id='stacks_out_1378_page0' class='stacks_out'><div id='stacks_in_1378_page0' class='stacks_in text_stack'>
						<a href="papers/contours_ev18.bib">[bib]</a>
						<a href="papers/contours_ev18.pdf">[pdf]</a>
						<a href="papers/contours_ev18.mp4">[mp4]</a>
						<br />
			    </div></div></div></div></div></div></div></div></div></div><div id='stacks_out_1032_page0' class='stacks_out'>

			      <!-- http://www.vis.uni-stuttgart.de/~freysn/ -->

			      <!-- end paper-->

			      <!-- begin paper-->

			    <div id='stacks_out_1357_page0' class='stacks_out'><div id='stacks_in_1357_page0' class='stacks_in '><div id='stacks_out_1358_page0' class='stacks_out'><div id='stacks_in_1358_page0' class='stacks_in stack_stack'><div id='stacks_out_1360_page0' class='stacks_out'><div id='stacks_in_1360_page0' class='stacks_in stack_stack'><div id='stacks_out_1362_page0' class='stacks_out'><div id='stacks_in_1362_page0' class='stacks_in stack_stack'>

					    <div id='stacks_out_1364_page0' class='stacks_out'><div id='stacks_in_1364_page0' class='stacks_in image_stack'><div class='centered_image' ><img class='imageStyle' src='pics/volumatrix.png' width='300' alt='Stacks Image 1365' /></div></div></div>

					    <!-- <div id='stacks_out_1366_page0' class='stacks_out'><div id='stacks_in_1366_page0' class='stacks_in image_stack'><div class='centered_image' ><img class='imageStyle' src='files/stacks_image_1367.png' width='300' height='150' alt='Stacks Image 1367' /></div></div></div> -->

					    <!-- <div id='stacks_out_1366_page0' class='stacks_out'><div id='stacks_in_1366_page0' class='stacks_in image_stack'><div class='centered_image' ><img class='imageStyle' src='pics/ev18/bottle.png' width='250' alt='Stacks Image 1367' /></div></div></div> -->


				    </div></div>


					<div id='stacks_out_1368_page0' class='stacks_out'><div id='stacks_in_1368_page0' class='stacks_in stack_stack'><div id='stacks_out_1370_page0' class='stacks_out'><div id='stacks_in_1370_page0' class='stacks_in text_stack'><span id='stacks_in_1371_page0'><strong>Volume-based Large Dynamic Graph Analytics</strong></span></div></div><div id='stacks_out_1372_page0' class='stacks_out'><div id='stacks_in_1372_page0' class='stacks_in text_stack'><em>V. Bruder, M. Hlawatsch, S. Frey, M. Burch, D. Weiskopf, T. Ertl</em></div></div><div id='stacks_out_1374_page0' class='stacks_out'><div id='stacks_in_1374_page0' class='stacks_in text_stack'>
						<a href="http://www.graphicslink.co.uk/IV2018/">IV 2018 </a><strong> | Best Paper</strong>
					    </div></div><div id='stacks_out_1376_page0' class='stacks_out'><div id='stacks_in_1376_page0' class='stacks_in text_stack'>
						We present an approach for interactively analyzing large dynamic graphs consisting of several thousand time steps, with a particular focus on temporal aspects. We employ a static representation of the time-varying graph based on the concept of space-time cubes, i.e., we create a volumetric representation of the graph by stacking the adjacency matrices of each of its time steps. To achieve an efficient analysis of this complex data, we discuss three classes of analytics methods of particular importance in this context: data views, aggregation and filtering, and comparison. For these classes, we provide respective analysis techniques, with our GPU-based implementation enabling the interactive analysis of large graphs. We demonstrate the utility as well as the scalability of our approach by presenting application examples for analyzing different time-varying data sets.
					    </div></div><div id='stacks_out_1378_page0' class='stacks_out'><div id='stacks_in_1378_page0' class='stacks_in text_stack'>
						<a href="papers/volumatrix.bib">[bib]</a>
						<a href="papers/volumatrix.pdf">[pdf]</a>
						<br />
			    </div></div></div></div></div></div></div></div></div></div><div id='stacks_out_1032_page0' class='stacks_out'>

			      <!-- http://www.vis.uni-stuttgart.de/~freysn/ -->

			      <!-- end paper-->

			    <!-- header year-->
			    <div id='stacks_out_9_page0' class='stacks_out'><div id='stacks_in_9_page0' class='stacks_in text_stack'><span id='stacks_in_10_page0'>2017</span></div></div>

			    <!-- begin paper-->

			    <div id='stacks_out_1357_page0' class='stacks_out'><div id='stacks_in_1357_page0' class='stacks_in '><div id='stacks_out_1358_page0' class='stacks_out'><div id='stacks_in_1358_page0' class='stacks_in stack_stack'><div id='stacks_out_1360_page0' class='stacks_out'><div id='stacks_in_1360_page0' class='stacks_in stack_stack'><div id='stacks_out_1362_page0' class='stacks_out'><div id='stacks_in_1362_page0' class='stacks_in stack_stack'>

					    <div id='stacks_out_1364_page0' class='stacks_out'><div id='stacks_in_1364_page0' class='stacks_in image_stack'><div class='centered_image' ><img class='imageStyle' src='pics/informatics17/rslt_graph.jpg' width='250' alt='Stacks Image 1365' /></div></div></div>

					    <!-- <div id='stacks_out_1366_page0' class='stacks_out'><div id='stacks_in_1366_page0' class='stacks_in image_stack'><div class='centered_image' ><img class='imageStyle' src='files/stacks_image_1367.png' width='300' height='150' alt='Stacks Image 1367' /></div></div></div> -->

					    <div id='stacks_out_1366_page0' class='stacks_out'><div id='stacks_in_1366_page0' class='stacks_in image_stack'><div class='centered_image' ><img class='imageStyle' src='pics/informatics17/rslt_sims.png' width='250' alt='Stacks Image 1367' /></div></div></div>


				    </div></div>


					<div id='stacks_out_1368_page0' class='stacks_out'><div id='stacks_in_1368_page0' class='stacks_in stack_stack'><div id='stacks_out_1370_page0' class='stacks_out'><div id='stacks_in_1370_page0' class='stacks_in text_stack'><span id='stacks_in_1371_page0'><strong>Sampling and Estimation of Pairwise Similarity in Spatio-Temporal Data Based on Neural Networks</strong></span></div></div><div id='stacks_out_1372_page0' class='stacks_out'><div id='stacks_in_1372_page0' class='stacks_in text_stack'><em>S. Frey</em></div></div><div id='stacks_out_1374_page0' class='stacks_out'><div id='stacks_in_1374_page0' class='stacks_in text_stack'>
						<a href="http://www.mdpi.com/2227-9709/4/3/27">Informatics (Special Issue Scalable Interactive Visualization)</a>
					    </div></div><div id='stacks_out_1376_page0' class='stacks_out'><div id='stacks_in_1376_page0' class='stacks_in text_stack'>
						Increasingly fast computing systems for simulations and high-accuracy measurement techniques drive the generation of time-dependent volumetric data sets with high resolution in both time and space. To gain insights from this spatio-temporal data, the computation and direct visualization of pairwise distances between time steps not only supports interactive user exploration, but also drives automatic analysis techniques like the generation of a meaningful static overview visualization, the identification of rare events, or the visual analysis of recurrent processes. However, the computation of pairwise differences between all time steps is prohibitively expensive for large-scale data not only due to the significant cost of computing expressive distance between high-resolution spatial data, but in particular owing to the large number of distance computations (O(|T|2)), with |T| being the number of time steps). Addressing this issue, we present and evaluate different strategies for the progressive computation of similarity information in a time series, as well as an approach for estimating distance information that has not been determined so far. In particular, we investigate and analyze the utility of using neural networks for estimating pairwise distances. On this basis, our approach automatically determines the sampling strategy yielding the best result in combination with trained networks for estimation.
					    </div></div><div id='stacks_out_1378_page0' class='stacks_out'><div id='stacks_in_1378_page0' class='stacks_in text_stack'>
						<a href="papers/frey_sim.bib">[bib]</a>
						<a href="papers/frey_sim.pdf">[pdf]</a>
						<br />
			    </div></div></div></div></div></div></div></div></div></div><div id='stacks_out_1032_page0' class='stacks_out'>

			      <!-- http://www.vis.uni-stuttgart.de/~freysn/ -->

			      <!-- end paper-->


			      <!-- begin paper-->

			    <div id='stacks_out_1357_page0' class='stacks_out'><div id='stacks_in_1357_page0' class='stacks_in '><div id='stacks_out_1358_page0' class='stacks_out'><div id='stacks_in_1358_page0' class='stacks_in stack_stack'><div id='stacks_out_1360_page0' class='stacks_out'><div id='stacks_in_1360_page0' class='stacks_in stack_stack'><div id='stacks_out_1362_page0' class='stacks_out'><div id='stacks_in_1362_page0' class='stacks_in stack_stack'>

					    <div id='stacks_out_1364_page0' class='stacks_out'><div id='stacks_in_1364_page0' class='stacks_in image_stack'><div class='centered_image' ><img class='imageStyle' src='pics/bruder_prediction_ext.png' width='300' alt='Stacks Image 1365' /></div></div></div>

					    <!-- <div id='stacks_out_1366_page0' class='stacks_out'><div id='stacks_in_1366_page0' class='stacks_in image_stack'><div class='centered_image' ><img class='imageStyle' src='files/stacks_image_1367.png' width='300' height='150' alt='Stacks Image 1367' /></div></div></div> -->

					    <!-- <div id='stacks_out_1366_page0' class='stacks_out'><div id='stacks_in_1366_page0' class='stacks_in image_stack'><div class='centered_image' ><img class='imageStyle' src='pics/cag17/teaser-ridge-time-plasma.png' width='300' alt='Stacks Image 1367' /></div></div></div> -->


				    </div></div>


					<div id='stacks_out_1368_page0' class='stacks_out'><div id='stacks_in_1368_page0' class='stacks_in stack_stack'><div id='stacks_out_1370_page0' class='stacks_out'><div id='stacks_in_1370_page0' class='stacks_in text_stack'><span id='stacks_in_1371_page0'><strong>Prediction-Based Load Balancing and Resolution Tuning for Interactive Volume Raycasting</strong></span></div></div><div id='stacks_out_1372_page0' class='stacks_out'><div id='stacks_in_1372_page0' class='stacks_in text_stack'><em>V. Bruder, S. Frey, T. Ertl </em></div></div><div id='stacks_out_1374_page0' class='stacks_out'><div id='stacks_in_1374_page0' class='stacks_in text_stack'>
						Visual Informatics
					    </div></div><div id='stacks_out_1376_page0' class='stacks_out'><div id='stacks_in_1376_page0' class='stacks_in text_stack'>
						We present an integrated approach for real-time performance prediction of volume raycasting that we employ for load balancing and sampling resolution tuning. In volume rendering, the usage of acceleration techniques such as empty space skipping and early ray termination, among others, can cause significant variations in rendering performance when users adjust the camera configuration or transfer function. These variations in rendering times may result in unpleasant effects such as jerky motions or abruptly reduced responsiveness during interactive exploration. To avoid those effects, we propose an integrated approach to adapt rendering parameters according to performance needs. We assess performance-relevant data on-the-fly, for which we propose a novel technique to estimate the impact of early ray termination. On the basis of this data, we introduce a hybrid model, to achieve accurate predictions with minimal computational footprint. Our hybrid model incorporates aspects from analytical performance modeling and machine learning, with the goal to combine their respective strengths. We show the applicability of our prediction model for two different use cases: (1) to dynamically steer the sampling density in object and/or image space and (2) to dynamically distribute the workload among several different parallel computing devices. Our approach allows the renderer to reliably meet performance requirements such as a user-defined frame rate, even in the case of sudden large changes to the transfer function or camera orientation.
					    </div></div><div id='stacks_out_1378_page0' class='stacks_out'><div id='stacks_in_1378_page0' class='stacks_in text_stack'>
						<a href="papers/bruder_prediction_ext.bib">[bib]</a>
						<a href="papers/bruder_prediction_ext.pdf">[pdf]</a>
						<br />
			    </div></div></div></div></div></div></div></div></div></div><div id='stacks_out_1032_page0' class='stacks_out'>

			      <!-- end paper-->

			      <!-- begin paper-->

			    <div id='stacks_out_1357_page0' class='stacks_out'><div id='stacks_in_1357_page0' class='stacks_in '><div id='stacks_out_1358_page0' class='stacks_out'><div id='stacks_in_1358_page0' class='stacks_in stack_stack'><div id='stacks_out_1360_page0' class='stacks_out'><div id='stacks_in_1360_page0' class='stacks_in stack_stack'><div id='stacks_out_1362_page0' class='stacks_out'><div id='stacks_in_1362_page0' class='stacks_in stack_stack'>

					    <div id='stacks_out_1364_page0' class='stacks_out'><div id='stacks_in_1364_page0' class='stacks_in image_stack'><div class='centered_image' ><img class='imageStyle' src='pics/heinemann_power.png' width='300' alt='Stacks Image 1365' /></div></div></div>

					    <!-- <div id='stacks_out_1366_page0' class='stacks_out'><div id='stacks_in_1366_page0' class='stacks_in image_stack'><div class='centered_image' ><img class='imageStyle' src='files/stacks_image_1367.png' width='300' height='150' alt='Stacks Image 1367' /></div></div></div> -->

					    <!-- <div id='stacks_out_1366_page0' class='stacks_out'><div id='stacks_in_1366_page0' class='stacks_in image_stack'><div class='centered_image' ><img class='imageStyle' src='pics/cag17/teaser-ridge-time-plasma.png' width='300' alt='Stacks Image 1367' /></div></div></div> -->


				    </div></div>


					<div id='stacks_out_1368_page0' class='stacks_out'><div id='stacks_in_1368_page0' class='stacks_in stack_stack'><div id='stacks_out_1370_page0' class='stacks_out'><div id='stacks_in_1370_page0' class='stacks_in text_stack'><span id='stacks_in_1371_page0'><strong>Power Efficiency of Volume Raycasting on Mobile Devices</strong></span></div></div><div id='stacks_out_1372_page0' class='stacks_out'><div id='stacks_in_1372_page0' class='stacks_in text_stack'><em>M. Heinemann, V. Bruder, S. Frey, T. Ertl </em></div></div><div id='stacks_out_1374_page0' class='stacks_out'><div id='stacks_in_1374_page0' class='stacks_in text_stack'>
						EuroVis 2017 - Posters
					    </div></div><div id='stacks_out_1376_page0' class='stacks_out'><div id='stacks_in_1376_page0' class='stacks_in text_stack'>
						Power efficiency is one of the most important factors for the development of compute-intensive applications in the mobile domain. In this work, we evaluate and discuss the power consumption of a direct volume rendering app based on raycasting on a mobile system. For this, we investigate the influence of a broad set of algorithmic parameters, which are relevant for performance and rendering quality, on the energy usage of the system. Additionally, we compare an OpenCL implementation to a variant using OpenGL. By means of a variety of examples, we demonstrate that numerous factors can have a significant impact on power consumption. In particular, we also discuss the underlying reasons for the respective effects.
					    </div></div><div id='stacks_out_1378_page0' class='stacks_out'><div id='stacks_in_1378_page0' class='stacks_in text_stack'>
						<a href="papers/heinemann_power.bib">[bib]</a>
						<a href="papers/heinemann_power.pdf">[pdf]</a>
						<br />
			    </div></div></div></div></div></div></div></div></div></div><div id='stacks_out_1032_page0' class='stacks_out'>

			      <!-- end paper-->

			    <!-- begin paper-->

			    <div id='stacks_out_1357_page0' class='stacks_out'><div id='stacks_in_1357_page0' class='stacks_in '><div id='stacks_out_1358_page0' class='stacks_out'><div id='stacks_in_1358_page0' class='stacks_in stack_stack'><div id='stacks_out_1360_page0' class='stacks_out'><div id='stacks_in_1360_page0' class='stacks_in stack_stack'><div id='stacks_out_1362_page0' class='stacks_out'><div id='stacks_in_1362_page0' class='stacks_in stack_stack'>

					    <div id='stacks_out_1364_page0' class='stacks_out'><div id='stacks_in_1364_page0' class='stacks_in image_stack'><div class='centered_image' ><img class='imageStyle' src='pics/cag17/bunny-ridge-velocity-viridis.png' width='200' alt='Stacks Image 1365' /></div></div></div>

					    <!-- <div id='stacks_out_1366_page0' class='stacks_out'><div id='stacks_in_1366_page0' class='stacks_in image_stack'><div class='centered_image' ><img class='imageStyle' src='files/stacks_image_1367.png' width='300' height='150' alt='Stacks Image 1367' /></div></div></div> -->

					    <div id='stacks_out_1366_page0' class='stacks_out'><div id='stacks_in_1366_page0' class='stacks_in image_stack'><div class='centered_image' ><img class='imageStyle' src='pics/cag17/teaser-ridge-time-plasma.png' width='300' alt='Stacks Image 1367' /></div></div></div>


				    </div></div>


					<div id='stacks_out_1368_page0' class='stacks_out'><div id='stacks_in_1368_page0' class='stacks_in stack_stack'><div id='stacks_out_1370_page0' class='stacks_out'><div id='stacks_in_1370_page0' class='stacks_in text_stack'><span id='stacks_in_1371_page0'><strong>Visualization of fracture progression in peridynamics</strong></span></div></div><div id='stacks_out_1372_page0' class='stacks_out'><div id='stacks_in_1372_page0' class='stacks_in text_stack'><em>M. Bußler, P. Diehl, D. Pflüger, S. Frey, F. Sadlo, T. Ertl, M. A. Schweitzer</em></div></div><div id='stacks_out_1374_page0' class='stacks_out'><div id='stacks_in_1374_page0' class='stacks_in text_stack'>
						Computers & Graphics
					    </div></div><div id='stacks_out_1376_page0' class='stacks_out'><div id='stacks_in_1376_page0' class='stacks_in text_stack'>
						We present a novel approach for the visualization of fracture processes in peridynamics simulations. In peridynamics simulation, materials are represented by material points linked with bonds, providing complex fracture behavior. Our approach first extracts the cracks from each time step by means of height ridge extraction. To avoid deterioration of the structures, we propose an approach to extract ridges from these data without resampling. The extracted crack geometries are then combined into a spatiotemporal structure, with special focus on temporal coherence and robustness. We then show how this structure can be used for various visualization approaches to reveal fracture dynamics, with a focus on physical mechanisms. We evaluate our approach and demonstrate its utility by means of different data sets.
					    </div></div><div id='stacks_out_1378_page0' class='stacks_out'><div id='stacks_in_1378_page0' class='stacks_in text_stack'>
						<a href="papers/bussler_peri.bib">[bib]</a>
						<a href="papers/bussler_peri.pdf">[pdf]</a>
						<br />
			    </div></div></div></div></div></div></div></div></div></div><div id='stacks_out_1032_page0' class='stacks_out'>

			      <!-- end paper-->

			    <!-- begin paper-->

			    <div id='stacks_out_1357_page0' class='stacks_out'><div id='stacks_in_1357_page0' class='stacks_in '><div id='stacks_out_1358_page0' class='stacks_out'><div id='stacks_in_1358_page0' class='stacks_in stack_stack'><div id='stacks_out_1360_page0' class='stacks_out'><div id='stacks_in_1360_page0' class='stacks_in stack_stack'><div id='stacks_out_1362_page0' class='stacks_out'><div id='stacks_in_1362_page0' class='stacks_in stack_stack'>

					    <div id='stacks_out_1364_page0' class='stacks_out'><div id='stacks_in_1364_page0' class='stacks_in image_stack'><div class='centered_image' ><img class='imageStyle' src='pics/egpgv17/diagram.png' width='300' alt='Stacks Image 1365' /></div></div></div>

					    <!-- <div id='stacks_out_1366_page0' class='stacks_out'><div id='stacks_in_1366_page0' class='stacks_in image_stack'><div class='centered_image' ><img class='imageStyle' src='files/stacks_image_1367.png' width='300' height='150' alt='Stacks Image 1367' /></div></div></div> -->

					    <div id='stacks_out_1366_page0' class='stacks_out'><div id='stacks_in_1366_page0' class='stacks_in image_stack'><div class='centered_image' ><img class='imageStyle' src='pics/egpgv17/chart_6144_1024.png' width='200' alt='Stacks Image 1367' /></div></div></div>


				    </div></div>


					<div id='stacks_out_1368_page0' class='stacks_out'><div id='stacks_in_1368_page0' class='stacks_in stack_stack'><div id='stacks_out_1370_page0' class='stacks_out'><div id='stacks_in_1370_page0' class='stacks_in text_stack'><span id='stacks_in_1371_page0'><strong>Prediction of Distributed Volume Visualization Performance to Support Render Hardware Acquisition</strong></span></div></div><div id='stacks_out_1372_page0' class='stacks_out'><div id='stacks_in_1372_page0' class='stacks_in text_stack'><em>G.Tkachev, S.Frey, C.Müller, V.Bruder, T.Ertl</em></div></div><div id='stacks_out_1374_page0' class='stacks_out'><div id='stacks_in_1374_page0' class='stacks_in text_stack'>
						Eurographics Symposium on Parallel Graphics and Visualization (EGPGV) 2017
					    </div></div><div id='stacks_out_1376_page0' class='stacks_out'><div id='stacks_in_1376_page0' class='stacks_in text_stack'>
						We present our data-driven, neural network-based approach to predicting the performance of a distributed GPU volume renderer for supporting cluster equipment acquisition. On the basis of timing measurements from a single cluster as well as from individual GPUs, we are able to predict the performance gain of upgrading an existing cluster with additional or faster GPUs, or even purchasing of a new cluster with a comparable network configuration. To achieve this, we employ neural networks to capture complex performance characteristics. However, merely relying on them for the prediction would require the collection of training data on multiple clusters with different hardware, which is impractical in most cases. Therefore, we propose a two-level approach to prediction, distinguishing between node and cluster level. On the node level, we generate performance histograms on individual nodes to capture local rendering performance. These performance histograms are then used to emulate the performance of different rendering hardware for cluster-level measurement runs. Crucially, this variety allows the neural network to capture the compositing performance of a cluster separately from the rendering performance on individual nodes. Therefore, we just need a performance histogram of the GPU of interest to generate a prediction. We demonstrate the utility of our approach using different cluster configurations as well as a range of image and volume resolutions.
					    </div></div><div id='stacks_out_1378_page0' class='stacks_out'><div id='stacks_in_1378_page0' class='stacks_in text_stack'>
						<a href="papers/tkachev_pred_dist_vol_vis.bib">[bib]</a>
						<a href="papers/tkachev_pred_dist_vol_vis.pdf">[pdf]</a>
						<br />
			    </div></div></div></div></div></div></div></div></div></div><div id='stacks_out_1032_page0' class='stacks_out'>

			      <!-- end paper-->

			       <!-- begin paper-->

			    <div id='stacks_out_1357_page0' class='stacks_out'><div id='stacks_in_1357_page0' class='stacks_in '><div id='stacks_out_1358_page0' class='stacks_out'><div id='stacks_in_1358_page0' class='stacks_in stack_stack'><div id='stacks_out_1360_page0' class='stacks_out'><div id='stacks_in_1360_page0' class='stacks_in stack_stack'><div id='stacks_out_1362_page0' class='stacks_out'><div id='stacks_in_1362_page0' class='stacks_in stack_stack'>

					    <div id='stacks_out_1364_page0' class='stacks_out'><div id='stacks_in_1364_page0' class='stacks_in image_stack'><div class='centered_image' ><img class='imageStyle' src='pics/egs17_iv/teaser.jpeg' width='200' alt='Stacks Image 1365' /></div></div></div>

					    <!-- <div id='stacks_out_1366_page0' class='stacks_out'><div id='stacks_in_1366_page0' class='stacks_in image_stack'><div class='centered_image' ><img class='imageStyle' src='files/stacks_image_1367.png' width='300' height='150' alt='Stacks Image 1367' /></div></div></div> -->

					    <!-- <div id='stacks_out_1366_page0' class='stacks_out'><div id='stacks_in_1366_page0' class='stacks_in image_stack'><div class='centered_image' ><img class='imageStyle' src='pics/egs17/single0.png' width='300' alt='Stacks Image 1367' /></div></div></div> -->

					    <!-- <div id='stacks_out_1366_page0' class='stacks_out'><div id='stacks_in_1366_page0' class='stacks_in image_stack'><div class='centered_image' ><img class='imageStyle' src='pics/egs17/single1.png' width='300' alt='Stacks Image 1367' /></div></div></div> -->

				    </div></div>


					<div id='stacks_out_1368_page0' class='stacks_out'><div id='stacks_in_1368_page0' class='stacks_in stack_stack'><div id='stacks_out_1370_page0' class='stacks_out'><div id='stacks_in_1370_page0' class='stacks_in text_stack'><span id='stacks_in_1371_page0'><strong>Fast Flow-based Distance Quantification and Interpolation for High-Resolution Density Distributions </strong></span></div></div><div id='stacks_out_1372_page0' class='stacks_out'><div id='stacks_in_1372_page0' class='stacks_in text_stack'><em>S. Frey, T. Ertl</em></div></div><div id='stacks_out_1374_page0' class='stacks_out'><div id='stacks_in_1374_page0' class='stacks_in text_stack'>
						EuroGraphics 2017, Short Paper<br>
						(also presented at NVIDIA GTC 2017)
					    </div></div><div id='stacks_out_1376_page0' class='stacks_out'><div id='stacks_in_1376_page0' class='stacks_in text_stack'>
						We present a GPU-targeted algorithm for the efficient direct computation of distances and interpolates between high-resolution density distributions without requiring any kind of intermediate representation like features. It is based on a previously published multi-core approach, and substantially improves its performance already on the same CPU hardware due to algorithmic improvements. As we explicitly target a manycore-friendly algorithm design, we further achieve significant speedups by running on a GPU. This paper quickly reviews the previous approach, and explicitly discusses the analysis of algorithmic characteristics as well as hardware architectural considerations on which our redesign was based. We demonstrate the performance and results of our technique by means of several transitions between volume data sets.
					    </div></div><div id='stacks_out_1378_page0' class='stacks_out'><div id='stacks_in_1378_page0' class='stacks_in text_stack'>
						<a href="papers/transvol_fast.bib">[bib]</a>
						<a href="papers/transvol_fast.pdf">[pdf]</a>
						<br />
			    </div></div></div></div></div></div></div></div></div></div><div id='stacks_out_1032_page0' class='stacks_out'>

				<!-- end paper-->

			    <!-- begin paper-->

			    <div id='stacks_out_1357_page0' class='stacks_out'><div id='stacks_in_1357_page0' class='stacks_in '><div id='stacks_out_1358_page0' class='stacks_out'><div id='stacks_in_1358_page0' class='stacks_in stack_stack'><div id='stacks_out_1360_page0' class='stacks_out'><div id='stacks_in_1360_page0' class='stacks_in stack_stack'><div id='stacks_out_1362_page0' class='stacks_out'><div id='stacks_in_1362_page0' class='stacks_in stack_stack'>

					    <div id='stacks_out_1364_page0' class='stacks_out'><div id='stacks_in_1364_page0' class='stacks_in image_stack'><div class='centered_image' ><img class='imageStyle' src='pics/egs17/knaeul.png' width='300' alt='Stacks Image 1365' /></div></div></div>

					    <!-- <div id='stacks_out_1366_page0' class='stacks_out'><div id='stacks_in_1366_page0' class='stacks_in image_stack'><div class='centered_image' ><img class='imageStyle' src='files/stacks_image_1367.png' width='300' height='150' alt='Stacks Image 1367' /></div></div></div> -->

					    <div id='stacks_out_1366_page0' class='stacks_out'><div id='stacks_in_1366_page0' class='stacks_in image_stack'><div class='centered_image' ><img class='imageStyle' src='pics/egs17/single0.png' width='300' alt='Stacks Image 1367' /></div></div></div>

					    <div id='stacks_out_1366_page0' class='stacks_out'><div id='stacks_in_1366_page0' class='stacks_in image_stack'><div class='centered_image' ><img class='imageStyle' src='pics/egs17/single1.png' width='300' alt='Stacks Image 1367' /></div></div></div>

				    </div></div>


					<div id='stacks_out_1368_page0' class='stacks_out'><div id='stacks_in_1368_page0' class='stacks_in stack_stack'><div id='stacks_out_1370_page0' class='stacks_out'><div id='stacks_in_1370_page0' class='stacks_in text_stack'><span id='stacks_in_1371_page0'><strong>Spline-based Decomposition of Streamed Particle Trajectories for Efficient Transfer and Analysis Conversion</strong></span></div></div><div id='stacks_out_1372_page0' class='stacks_out'><div id='stacks_in_1372_page0' class='stacks_in text_stack'><em>K. Scharnowski, S. Frey, B. Raffin, T. Ertl</em></div></div><div id='stacks_out_1374_page0' class='stacks_out'><div id='stacks_in_1374_page0' class='stacks_in text_stack'>
						EuroVis 2017, Short Paper
					    </div></div><div id='stacks_out_1376_page0' class='stacks_out'><div id='stacks_in_1376_page0' class='stacks_in text_stack'>
						We introduce an approach for distributed processing and efficient storage of noisy particle trajectories, and present visual analysis techniques that directly operate on the generated representation. For efficient storage, we decompose individual trajectories into a smooth representation and a high frequency part. Our smooth representation is generated by fitting Hermite Splines to a series of time windows, adhering to a certain error bound. This directly supports scenarios involving in situ and streaming data processing. We show how the individually fitted splines can afterwards be combined into one spline posessing the same mathematical properties, i.e. C1 continuity as well as our error bound. The fitted splines are typically significantly smaller than the original data, and can therefore be used, e.g., for an online monitoring and analysis of distributed particle simulations. The high frequency part can be used to reconstruct the original data, or could also be discarded in scenarios with limited storage capabilities. Finally, we demonstrate the utility of our smooth representation for different analysis queries using real world data.
					    </div></div><div id='stacks_out_1378_page0' class='stacks_out'><div id='stacks_in_1378_page0' class='stacks_in text_stack'>
						<a href="papers/spline_decomp.bib">[bib]</a>
						<a href="papers/spline_decomp.pdf">[pdf]</a>
						<br />
			    </div></div></div></div></div></div></div></div></div></div><div id='stacks_out_1032_page0' class='stacks_out'>

			      <!-- end paper-->

			    <div id='stacks_out_1357_page0' class='stacks_out'><div id='stacks_in_1357_page0' class='stacks_in '><div id='stacks_out_1358_page0' class='stacks_out'><div id='stacks_in_1358_page0' class='stacks_in stack_stack'><div id='stacks_out_1360_page0' class='stacks_out'><div id='stacks_in_1360_page0' class='stacks_in stack_stack'><div id='stacks_out_1362_page0' class='stacks_out'><div id='stacks_in_1362_page0' class='stacks_in stack_stack'><div id='stacks_out_1364_page0' class='stacks_out'><div id='stacks_in_1364_page0' class='stacks_in image_stack'><div class='centered_image' ><img class='imageStyle' src='files/stacks_image_1365.png' width='300' height='150' alt='Stacks Image 1365' /></div></div></div><div id='stacks_out_1366_page0' class='stacks_out'><div id='stacks_in_1366_page0' class='stacks_in image_stack'><div class='centered_image' ><img class='imageStyle' src='files/stacks_image_1367.png' width='300' height='150' alt='Stacks Image 1367' /></div></div></div></div></div><div id='stacks_out_1368_page0' class='stacks_out'><div id='stacks_in_1368_page0' class='stacks_in stack_stack'><div id='stacks_out_1370_page0' class='stacks_out'><div id='stacks_in_1370_page0' class='stacks_in text_stack'><span id='stacks_in_1371_page0'><strong>Transportation-based Visualization of Energy Conversion</strong></span></div></div><div id='stacks_out_1372_page0' class='stacks_out'><div id='stacks_in_1372_page0' class='stacks_in text_stack'><em>O. Fernandes, S. Frey, T. Ertl</em></div></div><div id='stacks_out_1374_page0' class='stacks_out'><div id='stacks_in_1374_page0' class='stacks_in text_stack'>IVAPP 2017</div></div><div id='stacks_out_1376_page0' class='stacks_out'><div id='stacks_in_1376_page0' class='stacks_in text_stack'>We present a novel technique to visualize the transport of and conversion between internal and kinetic energy in compressible flow data. While the distribution of energy can be directly derived from flow state variables (e.g., velocity, pressure and temperature) for each time step individually, there is no information regarding the involved transportation and conversion processes. To visualize these, we model the energy transportation problem as a graph that can be solved by a minimum cost flow algorithm, inherently respecting energy conservation. In doing this, we explicitly consider various simulation parameters like boundary conditions and energy transport mechanisms. Based on the resulting flux, we then derive a local measure for the conversion between energy forms using the distribution of internal and kinetic energy. To examine this data, we employ different visual mapping techniques that are specifically targeted towards different research questions. In particular, we introduce glyphs for visualizing local energy transport, which we place adaptively based on conversion rates to mitigate issues due to clutter and occlusion.</div></div><div id='stacks_out_1378_page0' class='stacks_out'><div id='stacks_in_1378_page0' class='stacks_in text_stack'></div></div></div></div></div></div></div></div></div></div><div id='stacks_out_1032_page0' class='stacks_out'>






			      <div id='stacks_in_1032_page0' class='stacks_in '><div id='stacks_out_1033_page0' class='stacks_out'><div id='stacks_in_1033_page0' class='stacks_in stack_stack'><div id='stacks_out_1035_page0' class='stacks_out'><div id='stacks_in_1035_page0' class='stacks_in stack_stack'><div id='stacks_out_1037_page0' class='stacks_out'><div id='stacks_in_1037_page0' class='stacks_in stack_stack'><div id='stacks_out_1039_page0' class='stacks_out'><div id='stacks_in_1039_page0' class='stacks_in image_stack'><div class='centered_image' ><img class='imageStyle' src='files/stacks_image_1040.png' width='216' height='434' alt='Stacks Image 1040' /></div></div></div></div></div><div id='stacks_out_1041_page0' class='stacks_out'><div id='stacks_in_1041_page0' class='stacks_in stack_stack'><div id='stacks_out_1043_page0' class='stacks_out'><div id='stacks_in_1043_page0' class='stacks_in text_stack'><span id='stacks_in_1044_page0'><strong>Progressive Direct Volume-to-Volume Transformation</strong></span></div></div><div id='stacks_out_1045_page0' class='stacks_out'><div id='stacks_in_1045_page0' class='stacks_in text_stack'><em>S. Frey, T. Ertl</em></div></div><div id='stacks_out_1623_page0' class='stacks_out'><div id='stacks_in_1623_page0' class='stacks_in text_stack'>TVCG (VIS 2016 paper)</div></div><div id='stacks_out_1049_page0' class='stacks_out'><div id='stacks_in_1049_page0' class='stacks_in text_stack'>We present a novel technique to generate transformations between arbitrary volumes, providing both expressive distances and smooth interpolates. In contrast to conventional morphing or warping approaches, our technique requires no user guidance, intermediate representations (like extracted features), or blending, and imposes no restrictions regarding shape or structure. Our technique operates directly on the volumetric data representation, and while linear programming approaches could solve the underlying problem optimally, their polynomial complexity makes them infeasible for high-resolution volumes. We therefore propose a progressive refinement approach designed for parallel execution that is able to quickly deliver approximate results that are iteratively improved toward the optimum. On this basis, we further present a new approach for the streaming selection of time steps in temporal data that allows for the reconstruction of the full sequence with a user-specified error bound. </div></div><div id='stacks_out_1051_page0' class='stacks_out'><div id='stacks_in_1051_page0' class='stacks_in text_stack'>
<a href="papers/transvol.bib">[bib]</a>
<a href="papers/transvol.pdf">[pdf]</a>
<a href="papers/transvol_vis16.mp4">[mp4]</a>

			    </div></div></div></div></div></div></div></div></div></div><div id='stacks_out_1266_page0' class='stacks_out'>


			      <div id='stacks_in_1266_page0' class='stacks_in text_stack'><span id='stacks_in_1267_page0'>2016</span></div></div>


			    <!-- begin paper-->

			    <div id='stacks_out_1357_page0' class='stacks_out'><div id='stacks_in_1357_page0' class='stacks_in '><div id='stacks_out_1358_page0' class='stacks_out'><div id='stacks_in_1358_page0' class='stacks_in stack_stack'><div id='stacks_out_1360_page0' class='stacks_out'><div id='stacks_in_1360_page0' class='stacks_in stack_stack'><div id='stacks_out_1362_page0' class='stacks_out'><div id='stacks_in_1362_page0' class='stacks_in stack_stack'>

					    <div id='stacks_out_1364_page0' class='stacks_out'><div id='stacks_in_1364_page0' class='stacks_in image_stack'><div class='centered_image' ><img class='imageStyle' src='pics/beliv16/workflow.png' width='300' alt='Stacks Image 1365' /></div></div></div>

					    <!-- <div id='stacks_out_1366_page0' class='stacks_out'><div id='stacks_in_1366_page0' class='stacks_in image_stack'><div class='centered_image' ><img class='imageStyle' src='files/stacks_image_1367.png' width='300' height='150' alt='Stacks Image 1367' /></div></div></div> -->

					    <!-- <div id='stacks_out_1366_page0' class='stacks_out'><div id='stacks_in_1366_page0' class='stacks_in image_stack'><div class='centered_image' ><img class='imageStyle' src='pics/informatics17/rslt_sims.png' width='250' alt='Stacks Image 1367' /></div></div></div> -->


				    </div></div>


					<div id='stacks_out_1368_page0' class='stacks_out'><div id='stacks_in_1368_page0' class='stacks_in stack_stack'><div id='stacks_out_1370_page0' class='stacks_out'><div id='stacks_in_1370_page0' class='stacks_in text_stack'><span id='stacks_in_1371_page0'><strong>Generative Data Models for Validation and Evaluation of Visualization Techniques</strong></span></div></div><div id='stacks_out_1372_page0' class='stacks_out'><div id='stacks_in_1372_page0' class='stacks_in text_stack'><em>C. Schulz, Christoph and A. Nocaj, M. El-Assady, S. Frey, M. Hlawatsch, M. Hund, G. Karch, R. Netzel,  C. Schätzle, M. Butt, D. Keim, T. Ertl, U. Brandes, D. Weiskopf</em></div></div><div id='stacks_out_1374_page0' class='stacks_out'><div id='stacks_in_1374_page0' class='stacks_in text_stack'>
						BELIV '16: Beyond Time And Errors: Novel Evaluation Methods For Visualization
					    </div></div><div id='stacks_out_1376_page0' class='stacks_out'><div id='stacks_in_1376_page0' class='stacks_in text_stack'>
						We argue that there is a need for substantially more research on the use of generative data models in the validation and evaluation of visualization techniques. For example, user studies will require the display of representative and uncon- founded visual stimuli, while algorithms will need functional coverage and assessable benchmarks. However, data is often collected in a semi-automatic fashion or entirely hand-picked, which obscures the view of generality, impairs availability, and potentially violates privacy. There are some sub-domains of visualization that use synthetic data in the sense of genera- tive data models, whereas others work with real-world-based data sets and simulations. Depending on the visualization domain, many generative data models are “side projects” as part of an ad-hoc validation of a techniques paper and thus neither reusable nor general-purpose. We review existing work on popular data collections and generative data models in visualization to discuss the opportunities and consequences for technique validation, evaluation, and experiment design. We distill handling and future directions, and discuss how we can engineer generative data models and how visualization research could benefit from more and better use of generative data models.
					    </div></div><div id='stacks_out_1378_page0' class='stacks_out'><div id='stacks_in_1378_page0' class='stacks_in text_stack'>
						<a href="papers/schulz_beliv.bib">[bib]</a>
						<a href="papers/schulz_beliv.pdf">[pdf]</a>
						<br />
			    </div></div></div></div></div></div></div></div></div></div><div id='stacks_out_1032_page0' class='stacks_out'>

			      <!-- end paper-->


			    <div id='stacks_out_1797_page0' class='stacks_out'><div id='stacks_in_1797_page0' class='stacks_in '><div id='stacks_out_1798_page0' class='stacks_out'><div id='stacks_in_1798_page0' class='stacks_in stack_stack'><div id='stacks_out_1800_page0' class='stacks_out'><div id='stacks_in_1800_page0' class='stacks_in stack_stack'><div id='stacks_out_1802_page0' class='stacks_out'><div id='stacks_in_1802_page0' class='stacks_in stack_stack'><div id='stacks_out_1804_page0' class='stacks_out'><div id='stacks_in_1804_page0' class='stacks_in image_stack'><div class='centered_image' ><img class='imageStyle' src='files/stacks_image_1805.png' width='300' height='144' alt='Stacks Image 1805' /></div></div></div></div></div>

					<div id='stacks_out_1808_page0' class='stacks_out'><div id='stacks_in_1808_page0' class='stacks_in stack_stack'><div id='stacks_out_1810_page0' class='stacks_out'><div id='stacks_in_1810_page0' class='stacks_in text_stack'><span id='stacks_in_1811_page0'><strong>Flow-based Temporal Selection for Interactive Volume Visualization</strong></span></div></div><div id='stacks_out_1812_page0' class='stacks_out'><div id='stacks_in_1812_page0' class='stacks_in text_stack'><em>S. Frey, T. Ertl</em></div></div><div id='stacks_out_1814_page0' class='stacks_out'><div id='stacks_in_1814_page0' class='stacks_in text_stack'>Computer Graphics Forum (presented at Eurographics 2017)</div></div><div id='stacks_out_1816_page0' class='stacks_out'><div id='stacks_in_1816_page0' class='stacks_in text_stack'>We present an approach to adaptively select time steps from time-dependent volume data sets for an integrated and comprehensive visualization. This reduced set of time steps not only saves cost, but also allows to show both the spatial structure and temporal development in one combined rendering. Our selection optimizes the coverage of the complete data on the basis of a minimum-cost flow-based technique to determine meaningful distances between time steps. As both optimal solutions of the involved transport and selection problem are prohibitively expensive, we present new approaches that are significantly faster with only minor deviations. We further propose an adaptive scheme for the progressive incorporation of new time steps. An interactive volume raycaster produces an integrated rendering of the selected time steps, and their computed differences are visualized in a dedicated chart to provide additional temporal similarity information.</div></div><div id='stacks_out_1818_page0' class='stacks_out'><div id='stacks_in_1818_page0' class='stacks_in text_stack'></div></div></div></div></div></div></div></div></div></div><div id='stacks_out_1708_page0' class='stacks_out'><div id='stacks_in_1708_page0' class='stacks_in '><div id='stacks_out_1709_page0' class='stacks_out'><div id='stacks_in_1709_page0' class='stacks_in stack_stack'><div id='stacks_out_1711_page0' class='stacks_out'><div id='stacks_in_1711_page0' class='stacks_in stack_stack'><div id='stacks_out_1713_page0' class='stacks_out'><div id='stacks_in_1713_page0' class='stacks_in stack_stack'><div id='stacks_out_1715_page0' class='stacks_out'><div id='stacks_in_1715_page0' class='stacks_in image_stack'><div class='centered_image' ><img class='imageStyle' src='files/stacks_image_1716.png' width='300' height='300' alt='Stacks Image 1716' /></div></div></div></div></div><div id='stacks_out_1717_page0' class='stacks_out'><div id='stacks_in_1717_page0' class='stacks_in stack_stack'><div id='stacks_out_1719_page0' class='stacks_out'><div id='stacks_in_1719_page0' class='stacks_in text_stack'><span id='stacks_in_1720_page0'><strong>Interpolation-Based Extraction of Representative Isosurfaces</strong></span></div></div><div id='stacks_out_1721_page0' class='stacks_out'><div id='stacks_in_1721_page0' class='stacks_in text_stack'><em>O. Fernandes, S. Frey, T. Ertl</em></div></div><div id='stacks_out_1723_page0' class='stacks_out'><div id='stacks_in_1723_page0' class='stacks_in text_stack'>ISVC 2016</div></div><div id='stacks_out_1725_page0' class='stacks_out'><div id='stacks_in_1725_page0' class='stacks_in text_stack'>We propose a novel technique for the automatic, similarity- based selection of representative surfaces. While our technique can be applied to any set of manifolds, we particularly focus on isosurfaces from volume data. We select representatives from sets of surfaces stemming from varying isovalues or time-dependent data. For selection, our approach interpolates between surfaces using a minimum cost flow solver, and determines whether the interpolate adequately represents the actual surface in-between. For this, we employ the Hausdorff distance as an intuitive measure of the similarity of two components. In contrast to popular contour tree-based approaches which are limited to changes in topology, our approach also accounts for geometric deviations. For interactive visualization, we employ a combination of surface renderings and a graph view that depicts the selected surfaces and their relation. </div></div><div id='stacks_out_1727_page0' class='stacks_out'><div id='stacks_in_1727_page0' class='stacks_in text_stack'><a href="papers/repiso.bib">[bib]</a><a href="papers/repiso.pdf">[pdf]</a></div></div></div></div></div></div></div></div></div></div><div id='stacks_out_1456_page0' class='stacks_out'><div id='stacks_in_1456_page0' class='stacks_in '><div id='stacks_out_1457_page0' class='stacks_out'><div id='stacks_in_1457_page0' class='stacks_in stack_stack'><div id='stacks_out_1459_page0' class='stacks_out'><div id='stacks_in_1459_page0' class='stacks_in stack_stack'><div id='stacks_out_1461_page0' class='stacks_out'><div id='stacks_in_1461_page0' class='stacks_in stack_stack'><div id='stacks_out_1463_page0' class='stacks_out'><div id='stacks_in_1463_page0' class='stacks_in image_stack'><div class='centered_image' ><img class='imageStyle' src='files/stacks_image_1464.jpg' width='150' height='212' alt='Stacks Image 1464' /></div></div></div></div></div><div id='stacks_out_1465_page0' class='stacks_out'><div id='stacks_in_1465_page0' class='stacks_in stack_stack'><div id='stacks_out_1467_page0' class='stacks_out'><div id='stacks_in_1467_page0' class='stacks_in text_stack'><span id='stacks_in_1468_page0'><strong>Partitioned Fluid-Structure-Acoustics Interaction on Distributed Data</strong></span></div></div><div id='stacks_out_1513_page0' class='stacks_out'><div id='stacks_in_1513_page0' class='stacks_in text_stack'><em>Blom, David S.; Ertl, Thomas; Fernandes, Oliver; Frey, Steffen; Klimach, Harald; Krupp, Verena; Mehl, Miriam; Roller, Sabine; Sternel, D&ouml;rte C.; Uekermann, Benjamin; Winter, Tilo; Van Zuijlen, Alexander H.</em></div></div><div id='stacks_out_1515_page0' class='stacks_out'><div id='stacks_in_1515_page0' class='stacks_in text_stack'>Software for Exascale Computing - SPPEXA 2013-2015</div></div><div id='stacks_out_1517_page0' class='stacks_out'><div id='stacks_in_1517_page0' class='stacks_in text_stack'>We present a coupled simulation approach for fluid-structure-acoustic interactions as an example for strongly surface coupled multi-physics problems. In addition to the multi-physics character, FSAI feature multi-scale properties as a further challenge. In our partitioned approach, the problem is split into spatially separated subdomains interacting via coupling surfaces. Within each subdomain, scalable, single physics solvers are used to solve the respective equation systems. We run this simulation with different solvers demonstrating the performance of various solvers and the flexibility of the partitioned approach with the coupling tool preCICE. An efficient and scalable in-situ visualization reducing the amount of data in place at the simulation processors before sending them over the network or to a file system completes the simulation environment.</div></div><div id='stacks_out_1519_page0' class='stacks_out'><div id='stacks_in_1519_page0' class='stacks_in text_stack'></div></div></div></div></div></div></div></div></div></div><div id='stacks_out_1590_page0' class='stacks_out'><div id='stacks_in_1590_page0' class='stacks_in '><div id='stacks_out_1591_page0' class='stacks_out'><div id='stacks_in_1591_page0' class='stacks_in stack_stack'><div id='stacks_out_1593_page0' class='stacks_out'><div id='stacks_in_1593_page0' class='stacks_in stack_stack'><div id='stacks_out_1595_page0' class='stacks_out'><div id='stacks_in_1595_page0' class='stacks_in stack_stack'><div id='stacks_out_1597_page0' class='stacks_out'><div id='stacks_in_1597_page0' class='stacks_in image_stack'><div class='centered_image' ><img class='imageStyle' src='files/stacks_image_1598.png' width='300' height='56' alt='Stacks Image 1598' /></div></div></div></div></div><div id='stacks_out_1599_page0' class='stacks_out'><div id='stacks_in_1599_page0' class='stacks_in stack_stack'><div id='stacks_out_1601_page0' class='stacks_out'><div id='stacks_in_1601_page0' class='stacks_in text_stack'><span id='stacks_in_1602_page0'><strong>Real-Time Performance Prediction and Tuning for Interactive Volume Raycasting</strong></span></div></div><div id='stacks_out_1603_page0' class='stacks_out'><div id='stacks_in_1603_page0' class='stacks_in text_stack'><em>V. Bruder, S. Frey, T. Ertl</em></div></div><div id='stacks_out_1615_page0' class='stacks_out'><div id='stacks_in_1615_page0' class='stacks_in text_stack'>SIGGRAPH ASIA 2016 Symposium on Visualization</div></div><div id='stacks_out_1605_page0' class='stacks_out'><div id='stacks_in_1605_page0' class='stacks_in text_stack'>We present an integrated approach for the real-time performance prediction and tuning of volume raycasting. The usage of empty space skipping and early ray termination, among others, can induce significant variations in performance when camera configuration and transfer functions are adjusted. <br />For interactive exploration, this can result in various unpleasant effects like abruptly reduced responsiveness or jerky motions. To overcome those effects, we propose an integrated approach to accelerate the rendering and assess performance-relevant data on-the-fly, including a new technique to estimate the impact of early ray termination. On this basis, we introduce a hybrid model, to achieve accurate predictions with only minimal computational footprint. Our hybrid model incorporates both aspects from analytical performance modeling and machine learning, with the goal to combine their respective strengths. Using our model, we dynamically steer the sampling density along rays with our automatic tuning technique.</div></div><div id='stacks_out_1607_page0' class='stacks_out'><div id='stacks_in_1607_page0' class='stacks_in text_stack'></div></div></div></div></div></div></div></div></div></div><div id='stacks_out_1469_page0' class='stacks_out'><div id='stacks_in_1469_page0' class='stacks_in '><div id='stacks_out_1470_page0' class='stacks_out'><div id='stacks_in_1470_page0' class='stacks_in stack_stack'><div id='stacks_out_1472_page0' class='stacks_out'><div id='stacks_in_1472_page0' class='stacks_in stack_stack'><div id='stacks_out_1474_page0' class='stacks_out'><div id='stacks_in_1474_page0' class='stacks_in stack_stack'><div id='stacks_out_1476_page0' class='stacks_out'><div id='stacks_in_1476_page0' class='stacks_in image_stack'><div class='centered_image' ><img class='imageStyle' src='files/stacks_image_1477.png' width='282' height='222' alt='Stacks Image 1477' /></div></div></div><div id='stacks_out_1478_page0' class='stacks_out'><div id='stacks_in_1478_page0' class='stacks_in image_stack'><div class='centered_image' ><img class='imageStyle' src='files/stacks_image_1500.png' width='300' height='92' alt='Stacks Image 1500' /></div></div></div></div></div><div id='stacks_out_1501_page0' class='stacks_out'><div id='stacks_in_1501_page0' class='stacks_in stack_stack'><div id='stacks_out_1503_page0' class='stacks_out'><div id='stacks_in_1503_page0' class='stacks_in text_stack'><span id='stacks_in_1504_page0'><strong>Auto-Tuning Intermediate Representations for In Situ Visualization</strong></span></div></div><div id='stacks_out_1505_page0' class='stacks_out'><div id='stacks_in_1505_page0' class='stacks_in text_stack'><em>S. Frey, T. Ertl</em></div></div><div id='stacks_out_1507_page0' class='stacks_out'><div id='stacks_in_1507_page0' class='stacks_in text_stack'>2016 New York Scientific Data Summit (NYSDS): Data-Driven Discovery</div></div><div id='stacks_out_1509_page0' class='stacks_out'><div id='stacks_in_1509_page0' class='stacks_in text_stack'>To optimize the generation of intermediate representations for hybrid in situ visualization, we present our approach to (1) analyze and quantify the impact of input parameters, and (2) to auto-tune them on this basis under the consideration of different constraints. We demonstrate its application and evaluate respective results at the example of Volumetric Depth Images (VDIs), a view-dependent representation for volumetric data. VDIs can quickly and flexibly be generated via a modified volume raycasting procedure that partitions and partially composits samples along view rays. In particular, we study the impact of respective input parameters on this process w.r.t. the involved quality-space trade-off. We quantify rendering quality via image quality metrics and space requirements via the compressed size of the intermediate representation. On this basis, we then automatically determine the parameter settings that yield the best quality under different constraints. We demonstrate the utility of our approach by means of a variety of different data sets, and show that we optimize the achieved results without having to rely on tedious and time-consuming manual tweaking.</div></div><div id='stacks_out_1511_page0' class='stacks_out'><div id='stacks_in_1511_page0' class='stacks_in text_stack'></div></div></div></div></div></div></div></div></div></div><div id='stacks_out_1214_page0' class='stacks_out'><div id='stacks_in_1214_page0' class='stacks_in '><div id='stacks_out_1215_page0' class='stacks_out'><div id='stacks_in_1215_page0' class='stacks_in stack_stack'><div id='stacks_out_1217_page0' class='stacks_out'><div id='stacks_in_1217_page0' class='stacks_in stack_stack'><div id='stacks_out_1219_page0' class='stacks_out'><div id='stacks_in_1219_page0' class='stacks_in stack_stack'><div id='stacks_out_1221_page0' class='stacks_out'><div id='stacks_in_1221_page0' class='stacks_in image_stack'><div class='centered_image' ><img class='imageStyle' src='files/stacks_image_1222.png' width='226' height='368' alt='Stacks Image 1222' /></div></div></div></div></div><div id='stacks_out_1223_page0' class='stacks_out'><div id='stacks_in_1223_page0' class='stacks_in stack_stack'><div id='stacks_out_1225_page0' class='stacks_out'><div id='stacks_in_1225_page0' class='stacks_in text_stack'><span id='stacks_in_1226_page0'><strong>Extraction of Fragments and Waves After Impact Damage in Particle-Based Simulations</strong></span></div></div><div id='stacks_out_1227_page0' class='stacks_out'><div id='stacks_in_1227_page0' class='stacks_in text_stack'><em>P. Diehl, M. Bu&szlig;ler, D. Pfl&uuml;ger, S. Frey, T. Ertl, F. Sadlo, M. A. Schweitzer</em></div></div><div id='stacks_out_1229_page0' class='stacks_out'><div id='stacks_in_1229_page0' class='stacks_in text_stack'>Meshfree Methods for Partial Differential Equations VIII, Springer International Publishing</div></div><div id='stacks_out_1252_page0' class='stacks_out'><div id='stacks_in_1252_page0' class='stacks_in text_stack'>The analysis of simulation results with complex geometries and the verification against experimental data is essential for impact damage and wave propagation. We present two visualization techniques for post-processing particle-based simulation data and highlight new aspects for the quantitative comparison with experimental data. Peridynamics, a non-local generalization of continuum mechanics, is considered as the reference particle method. The first approach is an extended connected component algorithm to extract the fragment size and the corresponding histograms. The distribution of the fragment size is experimental verifiable with these experiments. The second approach focus on the visualization of the stress after an impact in a complex geometry. Here the particle-based data is re-sampled and rendered with standard volume rendering techniques to address the interference pat- tern of the stress wave after the reflection at the boundary.</div></div><div id='stacks_out_1254_page0' class='stacks_out'><div id='stacks_in_1254_page0' class='stacks_in text_stack'><a href="papers/extraction_peri.bib">[bib]</a>
						<a href="papers/extraction_peri.pdf">[pdf]</a>
						<br /></div></div></div></div></div></div></div></div></div></div><div id='stacks_out_1005_page0' class='stacks_out'><div id='stacks_in_1005_page0' class='stacks_in text_stack'><span id='stacks_in_1006_page0'>2015</span></div></div><div id='stacks_out_1178_page0' class='stacks_out'><div id='stacks_in_1178_page0' class='stacks_in '><div id='stacks_out_1179_page0' class='stacks_out'><div id='stacks_in_1179_page0' class='stacks_in stack_stack'><div id='stacks_out_1181_page0' class='stacks_out'><div id='stacks_in_1181_page0' class='stacks_in stack_stack'><div id='stacks_out_1183_page0' class='stacks_out'><div id='stacks_in_1183_page0' class='stacks_in stack_stack'><div id='stacks_out_1185_page0' class='stacks_out'><div id='stacks_in_1185_page0' class='stacks_in image_stack'><div class='centered_image' ><img class='imageStyle' src='files/stacks_image_1186.jpg' width='300' height='256' alt='Stacks Image 1186' /></div></div></div></div></div><div id='stacks_out_1187_page0' class='stacks_out'><div id='stacks_in_1187_page0' class='stacks_in stack_stack'><div id='stacks_out_1189_page0' class='stacks_out'><div id='stacks_in_1189_page0' class='stacks_in text_stack'><span id='stacks_in_1190_page0'><strong>Balanced Sampling and Compression for Remote Visualization</strong></span></div></div><div id='stacks_out_1191_page0' class='stacks_out'><div id='stacks_in_1191_page0' class='stacks_in text_stack'><em>S. Frey, F. Sadlo, and T. Ertl</em></div></div><div id='stacks_out_1193_page0' class='stacks_out'><div id='stacks_in_1193_page0' class='stacks_in text_stack'><A TARGET="new" HREF="http://sa2015.siggraph.org/en/submitters/symposium-on-visualization-in-high-performance-computing.html"><span style="font-size:13px; ">SIGGRAPH Asia Symposium on Visualization in High Performance Computing</span></A>, Kobe, Japan, 2015.</div></div><div id='stacks_out_1195_page0' class='stacks_out'><div id='stacks_in_1195_page0' class='stacks_in text_stack'>We present a novel approach for handling sampling and compression in remote visualization in an integrative fashion. As adaptive sampling and compression share the same underlying concepts and criteria, the times spent for visualization and transfer can be balanced directly to optimize the image quality that can be achieved within a prescribed time window. Our dynamic adjustments regarding adaptive sampling, compression, and balancing, employ regression analysis-based error estimation which is carried out individually for each image block of a visualization frame. Our approach is tuned for high parallel efficiency in GPU-based remote visualization. We demonstrate its utility within a prototypical remote volume visualization pipeline by means of different datasets and configurations.</div></div><div id='stacks_out_1197_page0' class='stacks_out'><div id='stacks_in_1197_page0' class='stacks_in text_stack'><a href="papers/remote.pdf">[pdf]</a> <a href="papers/remote.mp4">[mp4]</a> <a href="papers/remote.bib">[bib]</a><br /></div></div></div></div></div></div></div></div></div></div><div id='stacks_out_1097_page0' class='stacks_out'><div id='stacks_in_1097_page0' class='stacks_in '><div id='stacks_out_1098_page0' class='stacks_out'><div id='stacks_in_1098_page0' class='stacks_in stack_stack'><div id='stacks_out_1100_page0' class='stacks_out'><div id='stacks_in_1100_page0' class='stacks_in stack_stack'><div id='stacks_out_1102_page0' class='stacks_out'><div id='stacks_in_1102_page0' class='stacks_in stack_stack'><div id='stacks_out_1104_page0' class='stacks_out'><div id='stacks_in_1104_page0' class='stacks_in image_stack'><div class='centered_image' ><img class='imageStyle' src='files/stacks_image_1105.jpg' width='300' height='214' alt='Stacks Image 1105' /></div></div></div></div></div><div id='stacks_out_1106_page0' class='stacks_out'><div id='stacks_in_1106_page0' class='stacks_in stack_stack'><div id='stacks_out_1108_page0' class='stacks_out'><div id='stacks_in_1108_page0' class='stacks_in text_stack'><span id='stacks_in_1109_page0'><strong>Exploratory Performance Analysis and Tuning of Parallel Interactive Volume Visualization on Large Displays</strong></span></div></div><div id='stacks_out_1110_page0' class='stacks_out'><div id='stacks_in_1110_page0' class='stacks_in text_stack'><em>A. Panagiotidis, S. Frey, and T. Ertl</em></div></div><div id='stacks_out_1112_page0' class='stacks_out'><div id='stacks_in_1112_page0' class='stacks_in text_stack'><A TARGET="new" HREF="http://www.eurovis2015.it">EuroVis 2015</A>, Short Paper, Cagliari, Sardinia, Italy, 2015.</div></div><div id='stacks_out_1114_page0' class='stacks_out'><div id='stacks_in_1114_page0' class='stacks_in text_stack'>In this paper, we present an integrated approach for exploratory performance analysis and parameter optimization of interactive distributed volume visualization for large displays. We collect performance metrics of interest on-the-fly directly from both the GPU and our volume ray casting implementation and visualize them simultaneously. This allows users to explore the data set together with the corresponding metrics to jointly investigate both the visual and the performance impact of different parameter settings, like camera position, sampling density, or acceleration technique.</div></div><div id='stacks_out_1116_page0' class='stacks_out'><div id='stacks_in_1116_page0' class='stacks_in text_stack'><a href="papers/perfanalysis.pdf">[pdf]</a></div></div></div></div></div></div></div></div></div></div><div id='stacks_out_1023_page0' class='stacks_out'><div id='stacks_in_1023_page0' class='stacks_in '><div id='stacks_out_1024_page0' class='stacks_out'><div id='stacks_in_1024_page0' class='stacks_in stack_stack'><div id='stacks_out_1026_page0' class='stacks_out'><div id='stacks_in_1026_page0' class='stacks_in stack_stack'><div id='stacks_out_1028_page0' class='stacks_out'><div id='stacks_in_1028_page0' class='stacks_in stack_stack'><div id='stacks_out_1030_page0' class='stacks_out'><div id='stacks_in_1030_page0' class='stacks_in image_stack'><div class='centered_image' ><img class='imageStyle' src='files/stacks_image_1031.png' width='224' height='162' alt='Stacks Image 1031' /></div></div></div></div></div><div id='stacks_out_1053_page0' class='stacks_out'><div id='stacks_in_1053_page0' class='stacks_in stack_stack'><div id='stacks_out_1055_page0' class='stacks_out'><div id='stacks_in_1055_page0' class='stacks_in text_stack'><span id='stacks_in_1056_page0'><strong>On In-Situ Visualization for Strongly Coupled Partitioned Fluid-Structure Interaction</strong></span></div></div><div id='stacks_out_1057_page0' class='stacks_out'><div id='stacks_in_1057_page0' class='stacks_in text_stack'><em>O. Fernandes, D.. Blom, S. Frey, A. V. Zuijlen, H. Bijl, and T. Ertl</em></div></div><div id='stacks_out_1061_page0' class='stacks_out'><div id='stacks_in_1061_page0' class='stacks_in text_stack'><A TARGET="new" HREF="http://congress.cimne.com/coupled2015/frontal/default.asp">VI International Conference on Computational Methods for Coupled Problems in Science and Engineering (COUPLED PROBLEMS 2015)</A>, Venice, Italy, 2015.</div></div><div id='stacks_out_1063_page0' class='stacks_out'><div id='stacks_in_1063_page0' class='stacks_in text_stack'>We present an integrated in-situ visualization approach for partitioned multi-physics simulation of fluid-structure interaction. The simulation itself is treated as a black box and only the information at the fluid-structure interface is considered, and communicated between the fluid and solid solvers with a separate coupling tool.</div></div><div id='stacks_out_1065_page0' class='stacks_out'><div id='stacks_in_1065_page0' class='stacks_in text_stack'><a href="papers/coupled.pdf">[pdf]</a></div></div></div></div></div></div></div></div></div></div><div id='stacks_out_828_page0' class='stacks_out'><div id='stacks_in_828_page0' class='stacks_in text_stack'><span id='stacks_in_829_page0'>2014</span></div></div><div id='stacks_out_1479_page0' class='stacks_out'><div id='stacks_in_1479_page0' class='stacks_in '><div id='stacks_out_1480_page0' class='stacks_out'><div id='stacks_in_1480_page0' class='stacks_in stack_stack'><div id='stacks_out_1482_page0' class='stacks_out'><div id='stacks_in_1482_page0' class='stacks_in stack_stack'><div id='stacks_out_1484_page0' class='stacks_out'><div id='stacks_in_1484_page0' class='stacks_in stack_stack'><div id='stacks_out_1486_page0' class='stacks_out'><div id='stacks_in_1486_page0' class='stacks_in image_stack'><div class='centered_image' ><img class='imageStyle' src='files/stacks_image_1487.jpg' width='230' height='332' alt='Stacks Image 1487' /></div></div></div></div></div><div id='stacks_out_1488_page0' class='stacks_out'><div id='stacks_in_1488_page0' class='stacks_in stack_stack'><div id='stacks_out_1490_page0' class='stacks_out'><div id='stacks_in_1490_page0' class='stacks_in text_stack'><span id='stacks_in_1491_page0'><strong>Interactive Progressive Visualization with Space-Time Error Control</strong></span></div></div><div id='stacks_out_1492_page0' class='stacks_out'><div id='stacks_in_1492_page0' class='stacks_in text_stack'><em>S. Frey, F. Sadlo, K.-L. Ma, and T. Ertl</em></div></div><div id='stacks_out_1494_page0' class='stacks_out'><div id='stacks_in_1494_page0' class='stacks_in text_stack'><A TARGET="new" HREF="http://visweek.org">IEEE Transactions on Visualization and Computer Graphics (Proceedings IEEE SciVis 2014)</A>, Paris, France, 2014.</div></div><div id='stacks_out_1496_page0' class='stacks_out'><div id='stacks_in_1496_page0' class='stacks_in text_stack'>Static settings with respect to a certain image quality or frame rate are inherently incapable of delivering both high frame rate for rapid changes and high image quality for detailed investigation. Our technique flexibly adapts by steering the visualization process in three major degrees of freedom: when to terminate the       <br />refinement of a frame in the background and start a new one, when to display a frame currently computed, and how much resources to consume. We base these decisions on the correlation of the errors due to insufficient sampling and response delay, which we estimate separately using fast yet expressive heuristics.</div></div><div id='stacks_out_1498_page0' class='stacks_out'><div id='stacks_in_1498_page0' class='stacks_in text_stack'><a href="papers/errorControl.pdf">[pdf]</a></div></div></div></div></div></div></div></div></div></div><div id='stacks_out_102_page0' class='stacks_out'><div id='stacks_in_102_page0' class='stacks_in '><div id='stacks_out_103_page0' class='stacks_out'><div id='stacks_in_103_page0' class='stacks_in stack_stack'><div id='stacks_out_127_page0' class='stacks_out'><div id='stacks_in_127_page0' class='stacks_in stack_stack'><div id='stacks_out_129_page0' class='stacks_out'><div id='stacks_in_129_page0' class='stacks_in stack_stack'><div id='stacks_out_131_page0' class='stacks_out'><div id='stacks_in_131_page0' class='stacks_in image_stack'><div class='centered_image' ><img class='imageStyle' src='files/stacks_image_132.png' width='350' height='118' alt='Stacks Image 132' /></div></div></div></div></div><div id='stacks_out_133_page0' class='stacks_out'><div id='stacks_in_133_page0' class='stacks_in stack_stack'><div id='stacks_out_135_page0' class='stacks_out'><div id='stacks_in_135_page0' class='stacks_in text_stack'><span id='stacks_in_136_page0'><strong>Space-Time Volumetric Depth Images for In-Situ Visualization</strong></span></div></div><div id='stacks_out_137_page0' class='stacks_out'><div id='stacks_in_137_page0' class='stacks_in text_stack'><em>O. Fernandes, S. Frey, F. Sadlo, and T. Ertl</em></div></div><div id='stacks_out_139_page0' class='stacks_out'><div id='stacks_in_139_page0' class='stacks_in text_stack'><A TARGET="new" HREF="http://www.ldav.org">IEEE Symposium on Large Data Analysis and Visualization</A>, Paris, France, 2014.</div></div><div id='stacks_out_156_page0' class='stacks_out'><div id='stacks_in_156_page0' class='stacks_in text_stack'>Volumetric depth images (VDI) are a view-dependent representation that combines the high quality of images with the explorability of 3D fields. By compressing the scalar data along view rays into sets of coherent supersegments, VDIs provide an efficient representation that supports a-posteriori changes of camera parameters. In this paper, we introduce space-time VDIs that achieve the data reduction that is required for efficient in-situ                 <br />visualization, while still maintaining spatiotemporal flexibility.</div></div><div id='stacks_out_158_page0' class='stacks_out'><div id='stacks_in_158_page0' class='stacks_in text_stack'><a href="papers/stvdi.pdf">[pdf]</a></div></div></div></div></div></div></div></div></div></div><div id='stacks_out_849_page0' class='stacks_out'><div id='stacks_in_849_page0' class='stacks_in text_stack'><span id='stacks_in_850_page0'>2013</span></div></div><div id='stacks_out_1562_page0' class='stacks_out'><div id='stacks_in_1562_page0' class='stacks_in '><div id='stacks_out_1563_page0' class='stacks_out'><div id='stacks_in_1563_page0' class='stacks_in stack_stack'><div id='stacks_out_1565_page0' class='stacks_out'><div id='stacks_in_1565_page0' class='stacks_in stack_stack'><div id='stacks_out_1567_page0' class='stacks_out'><div id='stacks_in_1567_page0' class='stacks_in stack_stack'><div id='stacks_out_1569_page0' class='stacks_out'><div id='stacks_in_1569_page0' class='stacks_in image_stack'><div class='centered_image' ><img class='imageStyle' src='files/stacks_image_1570.png' width='178' height='178' alt='Stacks Image 1570' /></div></div></div></div></div><div id='stacks_out_1571_page0' class='stacks_out'><div id='stacks_in_1571_page0' class='stacks_in stack_stack'><div id='stacks_out_1573_page0' class='stacks_out'><div id='stacks_in_1573_page0' class='stacks_in text_stack'><span id='stacks_in_1574_page0'><strong>Explorable Volumetric Depth Images from Raycasting</strong></span></div></div><div id='stacks_out_1575_page0' class='stacks_out'><div id='stacks_in_1575_page0' class='stacks_in text_stack'><em>S. Frey, F. Sadlo, and T. Ertl</em></div></div><div id='stacks_out_1577_page0' class='stacks_out'><div id='stacks_in_1577_page0' class='stacks_in text_stack'><A TARGET="new" HREF="http://www.ucsp.edu.pe/sibgrapi2013/">SIBGRAPI 2013 - Conference on Graphics, Patterns, and Images</A>, Arequipa, Peru, 2013.</div></div><div id='stacks_out_1579_page0' class='stacks_out'><div id='stacks_in_1579_page0' class='stacks_in text_stack'>View-dependent image-based rendering techniques have become increasingly popular as they combine the high quality of images with the explorability of interactive techniques. However, in the context of volume rendering, previous approaches suffer from various shortcomings, including the limitation to surfaces, expensive generation, and insufficient occlusion and motion parallax impairing depth perception. In this paper, we propose Volumetric Depth Images (VDI) to overcome these issues for view-dependent volume visualization by an extension of the Layered Depth Image (LDI) approach. Instead of only saving for each view ray of one camera configuration the depth and color values for a set of surfaces, as in LDIs, VDIs store so- called supersegments, each consisting of a depth range as well as composited color and opacity.</div></div><div id='stacks_out_1581_page0' class='stacks_out'><div id='stacks_in_1581_page0' class='stacks_in text_stack'><a href="papers/vdi.pdf">[pdf]</a></div></div></div></div></div></div></div></div></div></div><div id='stacks_out_1645_page0' class='stacks_out'><div id='stacks_in_1645_page0' class='stacks_in '><div id='stacks_out_1646_page0' class='stacks_out'><div id='stacks_in_1646_page0' class='stacks_in stack_stack'><div id='stacks_out_1648_page0' class='stacks_out'><div id='stacks_in_1648_page0' class='stacks_in stack_stack'><div id='stacks_out_1650_page0' class='stacks_out'><div id='stacks_in_1650_page0' class='stacks_in stack_stack'><div id='stacks_out_1652_page0' class='stacks_out'><div id='stacks_in_1652_page0' class='stacks_in image_stack'><div class='centered_image' ><img class='imageStyle' src='files/stacks_image_1653.png' width='300' height='180' alt='Stacks Image 1653' /></div></div></div></div></div><div id='stacks_out_1654_page0' class='stacks_out'><div id='stacks_in_1654_page0' class='stacks_in stack_stack'><div id='stacks_out_1656_page0' class='stacks_out'><div id='stacks_in_1656_page0' class='stacks_in text_stack'><span id='stacks_in_1657_page0'><strong>Mesh Generation From Layered Depth Images Using Isosurface Raycasting</strong></span></div></div><div id='stacks_out_1658_page0' class='stacks_out'><div id='stacks_in_1658_page0' class='stacks_in text_stack'><em>S. Frey, F. Sadlo, and T. Ertl</em></div></div><div id='stacks_out_1660_page0' class='stacks_out'><div id='stacks_in_1660_page0' class='stacks_in text_stack'><A TARGET="new" HREF="http://www.isvc.net/13/">ISVC 2013 - International Symposium on Visual Computing</A>, Rethymnon, Crete, Greece, 2013.</div></div><div id='stacks_out_1662_page0' class='stacks_out'><div id='stacks_in_1662_page0' class='stacks_in text_stack'>This paper presents an approach for the fast generation of meshes from Layered Depth Images (LDI), a representation that is inde- pendent of the underlying data structure and widely used in image-based rendering. LDIs can be quickly generated from high-quality, yet compu- tationally expensive isosurface raycasters that are available for a wide range of different types of data. We propose a fast technique to extract meshes from one or several LDIs which can then be rendered for fast, yet high-quality analysis with comparatively low hardware requirements. To further improve quality, we also investigate mesh geometry merging and adaptive refinement, both for triangle and quad meshes.</div></div><div id='stacks_out_1664_page0' class='stacks_out'><div id='stacks_in_1664_page0' class='stacks_in text_stack'><a href="papers/ldimesh.pdf">[pdf]</a></div></div></div></div></div></div></div></div></div></div><div id='stacks_out_1071_page0' class='stacks_out'><div id='stacks_in_1071_page0' class='stacks_in '><div id='stacks_out_1072_page0' class='stacks_out'><div id='stacks_in_1072_page0' class='stacks_in stack_stack'><div id='stacks_out_1074_page0' class='stacks_out'><div id='stacks_in_1074_page0' class='stacks_in stack_stack'><div id='stacks_out_1076_page0' class='stacks_out'><div id='stacks_in_1076_page0' class='stacks_in stack_stack'><div id='stacks_out_1078_page0' class='stacks_out'><div id='stacks_in_1078_page0' class='stacks_in image_stack'><div class='centered_image' ><img class='imageStyle' src='files/stacks_image_1079.png' width='300' height='224' alt='Stacks Image 1079' /></div></div></div></div></div><div id='stacks_out_1080_page0' class='stacks_out'><div id='stacks_in_1080_page0' class='stacks_in stack_stack'><div id='stacks_out_1082_page0' class='stacks_out'><div id='stacks_in_1082_page0' class='stacks_in text_stack'><span id='stacks_in_1085_page0'><strong>Parallel Interactive Visualization: Strategies and Examples</strong></span></div></div><div id='stacks_out_1086_page0' class='stacks_out'><div id='stacks_in_1086_page0' class='stacks_in text_stack'><em>S. Frey and T. Ertl</em></div></div><div id='stacks_out_1088_page0' class='stacks_out'><div id='stacks_in_1088_page0' class='stacks_in text_stack'>Interaction and HPC: Multi-Scale / Multi-Physics Applications, <A TARGET="new" HREF="http://www.mac.tum.de/parco2013/">ParCo 2013</A>, Munich, Germany, 2013. (Talk Only)</div></div><div id='stacks_out_1090_page0' class='stacks_out'><div id='stacks_in_1090_page0' class='stacks_in text_stack'>Scientific visualization applications typically exhibit a common structure and share a number of characteristic properties and requirements in the context of parallel computation. We outline these aspects by means of several applications from our scientific visualization research. We further show that, despite these shared commonalities, there exists a variety of significantly different approaches to improve the responsiveness in the context of parallel and distributed hardware architectures. This is exemplified by means of several of our visualization research projects.</div></div></div></div></div></div></div></div></div></div><div id='stacks_out_820_page0' class='stacks_out'><div id='stacks_in_820_page0' class='stacks_in text_stack'><span id='stacks_in_821_page0'>2012</span></div></div><div id='stacks_out_949_page0' class='stacks_out'><div id='stacks_in_949_page0' class='stacks_in '><div id='stacks_out_950_page0' class='stacks_out'><div id='stacks_in_950_page0' class='stacks_in stack_stack'><div id='stacks_out_952_page0' class='stacks_out'><div id='stacks_in_952_page0' class='stacks_in stack_stack'><div id='stacks_out_954_page0' class='stacks_out'><div id='stacks_in_954_page0' class='stacks_in stack_stack'><div id='stacks_out_956_page0' class='stacks_out'><div id='stacks_in_956_page0' class='stacks_in image_stack'><div class='centered_image' ><img class='imageStyle' src='files/stacks_image_957.png' width='302' height='180' alt='Stacks Image 957' /></div></div></div></div></div><div id='stacks_out_958_page0' class='stacks_out'><div id='stacks_in_958_page0' class='stacks_in stack_stack'><div id='stacks_out_960_page0' class='stacks_out'><div id='stacks_in_960_page0' class='stacks_in text_stack'><span id='stacks_in_961_page0'><strong>Visualization of Temporal Similarity in Field Data</strong></span></div></div><div id='stacks_out_962_page0' class='stacks_out'><div id='stacks_in_962_page0' class='stacks_in text_stack'><em>S. Frey, F. Sadlo and T. Ertl</em></div></div><div id='stacks_out_964_page0' class='stacks_out'><div id='stacks_in_964_page0' class='stacks_in text_stack'><A TARGET="new" HREF="http://visweek.org">IEEE Transactions on Visualization and Computer Graphics (Proceedings IEEE SciVis 2012)</A>, Seattle, USA, 2012.</div></div><div id='stacks_out_966_page0' class='stacks_out'><div id='stacks_in_966_page0' class='stacks_in text_stack'>Large parts of science and engineering deal with time-dependent phenomena. We present an interactive visualization approach for detecting and exploring similarity in the temporal variation of field data. It allows the investigation of periodic and quasi-periodic behavior at single points as well as similarity between different locations within a field or between different data sets.  </div></div><div id='stacks_out_968_page0' class='stacks_out'><div id='stacks_in_968_page0' class='stacks_in text_stack'><a href="papers/temporalSimilarity.pdf">[pdf]</a></div></div></div></div></div></div></div></div></div></div><div id='stacks_out_1147_page0' class='stacks_out'><div id='stacks_in_1147_page0' class='stacks_in '><div id='stacks_out_1148_page0' class='stacks_out'><div id='stacks_in_1148_page0' class='stacks_in stack_stack'><div id='stacks_out_1150_page0' class='stacks_out'><div id='stacks_in_1150_page0' class='stacks_in stack_stack'><div id='stacks_out_1152_page0' class='stacks_out'><div id='stacks_in_1152_page0' class='stacks_in stack_stack'><div id='stacks_out_1154_page0' class='stacks_out'><div id='stacks_in_1154_page0' class='stacks_in image_stack'><div class='centered_image' ><img class='imageStyle' src='files/stacks_image_1155.png' width='194' height='220' alt='Stacks Image 1155' /></div></div></div></div></div><div id='stacks_out_1156_page0' class='stacks_out'><div id='stacks_in_1156_page0' class='stacks_in stack_stack'><div id='stacks_out_1158_page0' class='stacks_out'><div id='stacks_in_1158_page0' class='stacks_in text_stack'><span id='stacks_in_1159_page0'><strong>SIMT Microscheduling: Reducing Thread Stalling in Divergent Iterative Algorithms</strong></span></div></div><div id='stacks_out_1160_page0' class='stacks_out'><div id='stacks_in_1160_page0' class='stacks_in text_stack'><em>S. Frey, G. Reina and T. Ertl</em></div></div><div id='stacks_out_1162_page0' class='stacks_out'><div id='stacks_in_1162_page0' class='stacks_in text_stack'><A TARGET="new" HREF="http://www.vis.uni-stuttgart.de/egpgv/egpgv2011/index.html">20th Euromicro International Conference on Parallel, Distributed and Network-Based Processing (PDP'12)</A>, Munich, Germany</div></div><div id='stacks_out_1164_page0' class='stacks_out'><div id='stacks_in_1164_page0' class='stacks_in text_stack'>Current GPUs execute group of threads (warps) in lockstep. This potential leads to a large amount of wasted cycles for divergent control flow. To overcome this issue, we propose techniques to relax divergence on the fly within a computation kernel to achieve a much higher utilization of processing cores.</div></div><div id='stacks_out_1166_page0' class='stacks_out'><div id='stacks_in_1166_page0' class='stacks_in text_stack'><a href="papers/simt.pdf">[pdf]</a> <a href="papers/simt.bib">[bibtex]</a></div></div></div></div></div></div></div></div></div></div><div id='stacks_out_1230_page0' class='stacks_out'><div id='stacks_in_1230_page0' class='stacks_in '><div id='stacks_out_1231_page0' class='stacks_out'><div id='stacks_in_1231_page0' class='stacks_in stack_stack'><div id='stacks_out_1233_page0' class='stacks_out'><div id='stacks_in_1233_page0' class='stacks_in stack_stack'><div id='stacks_out_1235_page0' class='stacks_out'><div id='stacks_in_1235_page0' class='stacks_in stack_stack'><div id='stacks_out_1237_page0' class='stacks_out'><div id='stacks_in_1237_page0' class='stacks_in image_stack'><div class='centered_image' ><img class='imageStyle' src='files/stacks_image_1238.png' width='240' height='186' alt='Stacks Image 1238' /></div></div></div></div></div><div id='stacks_out_1239_page0' class='stacks_out'><div id='stacks_in_1239_page0' class='stacks_in stack_stack'><div id='stacks_out_1241_page0' class='stacks_out'><div id='stacks_in_1241_page0' class='stacks_in text_stack'><span id='stacks_in_1242_page0'><strong>GPU-Accelerated Visualization</strong></span></div></div><div id='stacks_out_1243_page0' class='stacks_out'><div id='stacks_in_1243_page0' class='stacks_in text_stack'><em>Ament, Marco; Frey, Steffen; M&uuml;ller, Christoph; Grottel, Sebastian; Ertl, Thomas; Weiskopf, Daniel</em></div></div><div id='stacks_out_1245_page0' class='stacks_out'><div id='stacks_in_1245_page0' class='stacks_in text_stack'><em>In Book:</em> E. W. Bethel, H. Childs, and C. Hansen: High Performance Visualization: Enabling Extreme-Scale Scientific Insight. Chapman and Hall/CRC (2012).</div></div><div id='stacks_out_1247_page0' class='stacks_out'><div id='stacks_in_1247_page0' class='stacks_in text_stack'>The book explores several distinct but interrelated approaches to high performance visualization. In my section, I give an overview on programming frameworks for GPU clusters with focus on visualization.</div></div><div id='stacks_out_1249_page0' class='stacks_out'><div id='stacks_in_1249_page0' class='stacks_in text_stack'><a href="papers/highperformance.bib">[bibtex]</a></div></div></div></div></div></div></div></div></div></div><div id='stacks_out_1059_page0' class='stacks_out'><div id='stacks_in_1059_page0' class='stacks_in text_stack'><span id='stacks_in_1060_page0'>2011</span></div></div><div id='stacks_out_731_page0' class='stacks_out'><div id='stacks_in_731_page0' class='stacks_in '><div id='stacks_out_732_page0' class='stacks_out'><div id='stacks_in_732_page0' class='stacks_in stack_stack'><div id='stacks_out_734_page0' class='stacks_out'><div id='stacks_in_734_page0' class='stacks_in stack_stack'><div id='stacks_out_736_page0' class='stacks_out'><div id='stacks_in_736_page0' class='stacks_in stack_stack'><div id='stacks_out_738_page0' class='stacks_out'><div id='stacks_in_738_page0' class='stacks_in image_stack'><div class='centered_image' ><img class='imageStyle' src='files/stacks_image_739.png' width='350' height='204' alt='Stacks Image 739' /></div></div></div></div></div><div id='stacks_out_740_page0' class='stacks_out'><div id='stacks_in_740_page0' class='stacks_in stack_stack'><div id='stacks_out_742_page0' class='stacks_out'><div id='stacks_in_742_page0' class='stacks_in text_stack'><span id='stacks_in_743_page0'><strong>Loose Capacity-Constrained Representatives for the Qualitative Visual Analysis in Molecular Dynamics</strong></span></div></div><div id='stacks_out_744_page0' class='stacks_out'><div id='stacks_in_744_page0' class='stacks_in text_stack'><em>S. Frey, T. Schl&ouml;mer, S. Grottel, C. Dachsbacher, O. Deussen and T. Ertl</em></div></div><div id='stacks_out_746_page0' class='stacks_out'><div id='stacks_in_746_page0' class='stacks_in text_stack'><A TARGET="new" HREF="http://i.cs.hku.hk/~pvis2011/">4th IEEE Pacific Visualization Symposium</A>, Hong Kong, 2011.</div></div><div id='stacks_out_748_page0' class='stacks_out'><div id='stacks_in_748_page0' class='stacks_in text_stack'>The increasing extents of the spatial and temporal domain of molecular dynamics simulations pose a particular challenge for the visualization. Our technique replaces the huge amount of simulated particles by a smaller set of representatives that capture the characteristics of the underlying particle density and exhibit coherency over time.</div></div><div id='stacks_out_750_page0' class='stacks_out'><div id='stacks_in_750_page0' class='stacks_in text_stack'><a href="papers/lccvd.pdf">[pdf]</a> <a href="papers/lccvd.bib">[bibtex]</a></div></div></div></div></div></div></div></div></div></div><div id='stacks_out_563_page0' class='stacks_out'><div id='stacks_in_563_page0' class='stacks_in '><div id='stacks_out_564_page0' class='stacks_out'><div id='stacks_in_564_page0' class='stacks_in stack_stack'><div id='stacks_out_566_page0' class='stacks_out'><div id='stacks_in_566_page0' class='stacks_in stack_stack'><div id='stacks_out_568_page0' class='stacks_out'><div id='stacks_in_568_page0' class='stacks_in stack_stack'><div id='stacks_out_928_page0' class='stacks_out'><div id='stacks_in_928_page0' class='stacks_in image_stack'><div class='centered_image' ><img class='imageStyle' src='files/stacks_image_929.png' width='140' height='220' alt='Stacks Image 929' /></div></div></div></div></div><div id='stacks_out_572_page0' class='stacks_out'><div id='stacks_in_572_page0' class='stacks_in stack_stack'><div id='stacks_out_574_page0' class='stacks_out'><div id='stacks_in_574_page0' class='stacks_in text_stack'><span id='stacks_in_575_page0'><strong>Load Balancing Utilizing Data Redundancy in Distributed Volume Rendering</strong></span></div></div><div id='stacks_out_576_page0' class='stacks_out'><div id='stacks_in_576_page0' class='stacks_in text_stack'><em>S. Frey and T. Ertl</em></div></div><div id='stacks_out_578_page0' class='stacks_out'><div id='stacks_in_578_page0' class='stacks_in text_stack'><A TARGET="new" HREF="http://www.vis.uni-stuttgart.de/egpgv/egpgv2011/index.html">Eurographics 2011 Symposium on Parallel Graphics and Visualization (EGPGV'11)</A>, Bangor, Wales, 2011.</div></div><div id='stacks_out_580_page0' class='stacks_out'><div id='stacks_in_580_page0' class='stacks_in text_stack'>In distributed volume rendering, the cost for rendering different blocks of the volumes strongly varies with the camera configuration. Traditional load-balancing induces expensive data transfers. Our technique stores volume blocks redundantly, allowing our scheduler to evenly balance the load with almost no overhead.</div></div><div id='stacks_out_582_page0' class='stacks_out'><div id='stacks_in_582_page0' class='stacks_in text_stack'><a href="papers/redundancy.pdf">[pdf]</a> <a href="papers/redundancy.bib">[bibtex]</a></div></div></div></div></div></div></div></div></div></div><div id='stacks_out_437_page0' class='stacks_out'><div id='stacks_in_437_page0' class='stacks_in '><div id='stacks_out_438_page0' class='stacks_out'><div id='stacks_in_438_page0' class='stacks_in stack_stack'><div id='stacks_out_440_page0' class='stacks_out'><div id='stacks_in_440_page0' class='stacks_in stack_stack'><div id='stacks_out_442_page0' class='stacks_out'><div id='stacks_in_442_page0' class='stacks_in stack_stack'><div id='stacks_out_444_page0' class='stacks_out'><div id='stacks_in_444_page0' class='stacks_in image_stack'><div class='centered_image' ><img class='imageStyle' src='files/stacks_image_445.jpg' width='498' height='166' alt='Stacks Image 445' /></div></div></div></div></div><div id='stacks_out_446_page0' class='stacks_out'><div id='stacks_in_446_page0' class='stacks_in stack_stack'><div id='stacks_out_448_page0' class='stacks_out'><div id='stacks_in_448_page0' class='stacks_in text_stack'><span id='stacks_in_449_page0'><strong>GPU-based 2D Flow Simulation Steering using Coherent Structures</strong></span></div></div><div id='stacks_out_450_page0' class='stacks_out'><div id='stacks_in_450_page0' class='stacks_in text_stack'><em>M. Ament, S. Frey, F. Sadlo, T. Ertl and D. Weiskopf</em></div></div><div id='stacks_out_452_page0' class='stacks_out'><div id='stacks_in_452_page0' class='stacks_in text_stack'><A TARGET="new" HREF="http://www.civil-comp.com/conf/pareng2011.htm">Second International Conference on Parallel, Distributed, Grid and Cloud Computing for Engineering</A>, Ajaccio, Corsica, France, 2011.</div></div><div id='stacks_out_454_page0' class='stacks_out'><div id='stacks_in_454_page0' class='stacks_in text_stack'>The interactive investigation of  CFD flow can both allow to achieve a desired flow behavior faster and supports the understanding of underlying mechanisms. We propose a CUDA-based steering system that allows interactive manipulation of boundary conditions such as obstacles or velocity profiles.</div></div><div id='stacks_out_456_page0' class='stacks_out'><div id='stacks_in_456_page0' class='stacks_in text_stack'><a href="papers/steering.pdf">[pdf]</a> <a href="papers/steering.bib">[bibtex]</a></div></div></div></div></div></div></div></div></div></div><div id='stacks_out_1396_page0' class='stacks_out'><div id='stacks_in_1396_page0' class='stacks_in '><div id='stacks_out_1397_page0' class='stacks_out'><div id='stacks_in_1397_page0' class='stacks_in stack_stack'><div id='stacks_out_1399_page0' class='stacks_out'><div id='stacks_in_1399_page0' class='stacks_in stack_stack'><div id='stacks_out_1401_page0' class='stacks_out'><div id='stacks_in_1401_page0' class='stacks_in stack_stack'><div id='stacks_out_1403_page0' class='stacks_out'><div id='stacks_in_1403_page0' class='stacks_in image_stack'><div class='centered_image' ><img class='imageStyle' src='files/stacks_image_1404.png' width='300' height='86' alt='Stacks Image 1404' /></div></div></div></div></div><div id='stacks_out_1405_page0' class='stacks_out'><div id='stacks_in_1405_page0' class='stacks_in stack_stack'><div id='stacks_out_1407_page0' class='stacks_out'><div id='stacks_in_1407_page0' class='stacks_in text_stack'><span id='stacks_in_1408_page0'><strong>DIANA: A Device Abstraction Framework for Parallel Computations</strong></span></div></div><div id='stacks_out_1409_page0' class='stacks_out'><div id='stacks_in_1409_page0' class='stacks_in text_stack'><em>A. Panagiotidis, D. Kauker, S. Frey, T. Ertl</em></div></div><div id='stacks_out_1411_page0' class='stacks_out'><div id='stacks_in_1411_page0' class='stacks_in text_stack'><A TARGET="new" HREF="http://www.civil-comp.com/conf/pareng2011.htm">Second International Conference on Parallel, Distributed, Grid and Cloud Computing for Engineering</A>, Ajaccio, Corsica, France, 2011.</div></div><div id='stacks_out_1413_page0' class='stacks_out'><div id='stacks_in_1413_page0' class='stacks_in text_stack'>There is a multitude of different APIs, SDKs and libraries for programming different many-core devices. DIANA provides a common interface to hide the complexity of managing them, allowing for easier maintainability, higher flexibility and improved portability. </div></div><div id='stacks_out_1415_page0' class='stacks_out'><div id='stacks_in_1415_page0' class='stacks_in text_stack'><a href="papers/diana.bib">[bibtex]</a></div></div></div></div></div></div></div></div></div></div><div id='stacks_out_1067_page0' class='stacks_out'><div id='stacks_in_1067_page0' class='stacks_in text_stack'><span id='stacks_in_1068_page0'>2010</span></div></div><div id='stacks_out_689_page0' class='stacks_out'><div id='stacks_in_689_page0' class='stacks_in '><div id='stacks_out_690_page0' class='stacks_out'><div id='stacks_in_690_page0' class='stacks_in stack_stack'><div id='stacks_out_692_page0' class='stacks_out'><div id='stacks_in_692_page0' class='stacks_in stack_stack'><div id='stacks_out_694_page0' class='stacks_out'><div id='stacks_in_694_page0' class='stacks_in stack_stack'><div id='stacks_out_696_page0' class='stacks_out'><div id='stacks_in_696_page0' class='stacks_in image_stack'><div class='centered_image' ><img class='imageStyle' src='files/stacks_image_697.png' width='162' height='220' alt='Stacks Image 697' /></div></div></div></div></div><div id='stacks_out_698_page0' class='stacks_out'><div id='stacks_in_698_page0' class='stacks_in stack_stack'><div id='stacks_out_700_page0' class='stacks_out'><div id='stacks_in_700_page0' class='stacks_in text_stack'><span id='stacks_in_701_page0'><strong>Interactive High-Quality Visualization of Higher-Order Finite Elements</strong></span></div></div><div id='stacks_out_702_page0' class='stacks_out'><div id='stacks_in_702_page0' class='stacks_in text_stack'><em>M. &Uuml;ffinger, S. Frey, and T. Ertl </em></div></div><div id='stacks_out_704_page0' class='stacks_out'><div id='stacks_in_704_page0' class='stacks_in text_stack'><A TARGET="new" HREF="http://www.eurographics2010.se/">Eurographics 2010 (EG'10)</A>, Nork&ouml;pping, Sweden, 2010.</div></div><div id='stacks_out_706_page0' class='stacks_out'><div id='stacks_in_706_page0' class='stacks_in text_stack'>Higher-order finite element methods produce complex grids which feature non-convex, curvilinear cells with varying polynomial degree. We introduce a distributed GPU-based ray casting system employing both adaptive sampling and load-balancing for achieving interactive frame rates.</div></div><div id='stacks_out_708_page0' class='stacks_out'><div id='stacks_in_708_page0' class='stacks_in text_stack'><a href="papers/higherorder.pdf">[pdf]</a> <a href="papers/higherorder.bib">[bibtex]</a></div></div></div></div></div></div></div></div></div></div><div id='stacks_out_647_page0' class='stacks_out'><div id='stacks_in_647_page0' class='stacks_in '><div id='stacks_out_648_page0' class='stacks_out'><div id='stacks_in_648_page0' class='stacks_in stack_stack'><div id='stacks_out_650_page0' class='stacks_out'><div id='stacks_in_650_page0' class='stacks_in stack_stack'><div id='stacks_out_652_page0' class='stacks_out'><div id='stacks_in_652_page0' class='stacks_in stack_stack'><div id='stacks_out_654_page0' class='stacks_out'><div id='stacks_in_654_page0' class='stacks_in image_stack'><div class='centered_image' ><img class='imageStyle' src='files/stacks_image_655.png' width='292' height='194' alt='Stacks Image 655' /></div></div></div></div></div><div id='stacks_out_656_page0' class='stacks_out'><div id='stacks_in_656_page0' class='stacks_in stack_stack'><div id='stacks_out_658_page0' class='stacks_out'><div id='stacks_in_658_page0' class='stacks_in text_stack'><span id='stacks_in_659_page0'><strong>Memory Saving Fourier Transform on GPUs</strong></span></div></div><div id='stacks_out_660_page0' class='stacks_out'><div id='stacks_in_660_page0' class='stacks_in text_stack'><em>D. Kauker, H. Sanftmann, S. Frey, and T. Ertl</em></div></div><div id='stacks_out_662_page0' class='stacks_out'><div id='stacks_in_662_page0' class='stacks_in text_stack'><A TARGET="new" HREF="http://www.comp.hkbu.edu.hk/~chxw/fgc2010/index.php">Frontier of GPU Computing 2010 (FGC'10)</A>, Bradford, UK, 2010.<br /><A TARGET="new" HREF="http://www.nvidia.com/object/gpu_technology_conference.html">NVIDIA GPU Technology Conference (GTC'09)</A>, San Jose, USA, 2009.</div></div><div id='stacks_out_664_page0' class='stacks_out'><div id='stacks_in_664_page0' class='stacks_in text_stack'>Current GPU Fourier transform libraries need a large buffer for storing intermediate results, severely limiting the size of an image that can be processed for instance. Our alternative two-dimensional Discrete Fourier Transform method computes the same output with far less memory by exploiting the separability property.</div></div><div id='stacks_out_666_page0' class='stacks_out'><div id='stacks_in_666_page0' class='stacks_in text_stack'><a href="papers/redundancy.pdf">[pdf]</a> <a href="papers/flexft.bib">[bibtex]</a></div></div></div></div></div></div></div></div></div></div><div id='stacks_out_1313_page0' class='stacks_out'><div id='stacks_in_1313_page0' class='stacks_in '><div id='stacks_out_1314_page0' class='stacks_out'><div id='stacks_in_1314_page0' class='stacks_in stack_stack'><div id='stacks_out_1316_page0' class='stacks_out'><div id='stacks_in_1316_page0' class='stacks_in stack_stack'><div id='stacks_out_1318_page0' class='stacks_out'><div id='stacks_in_1318_page0' class='stacks_in stack_stack'><div id='stacks_out_1320_page0' class='stacks_out'><div id='stacks_in_1320_page0' class='stacks_in image_stack'><div class='centered_image' ><img class='imageStyle' src='files/stacks_image_1321.png' width='300' height='162' alt='Stacks Image 1321' /></div></div></div></div></div><div id='stacks_out_1322_page0' class='stacks_out'><div id='stacks_in_1322_page0' class='stacks_in stack_stack'><div id='stacks_out_1324_page0' class='stacks_out'><div id='stacks_in_1324_page0' class='stacks_in text_stack'><span id='stacks_in_1325_page0'><strong>PaTraCo: A Framework Enabling the Transparent and Efficient Programming of Heterogeneous Compute Networks</strong></span></div></div><div id='stacks_out_1326_page0' class='stacks_out'><div id='stacks_in_1326_page0' class='stacks_in text_stack'><em>S. Frey and T. Ertl</em></div></div><div id='stacks_out_1328_page0' class='stacks_out'><div id='stacks_in_1328_page0' class='stacks_in text_stack'><A TARGET="new" HREF="http://www.vis.uni-stuttgart.de/egpgv/egpgv2010/index.html">Eurographics 2010 Symposium on Parallel Graphics and Visualization (EGPGV'10)</A>, Nork&ouml;pping, Sweden</div></div><div id='stacks_out_1330_page0' class='stacks_out'><div id='stacks_in_1330_page0' class='stacks_in text_stack'>In particular ad-hoc compute networks are typically heterogeneous, e.g. different classes of compute devices at different speeds suited for different kinds of tasks, varying network bandwidth). We propose a framework with a built-in scheduler that explicitly considers these characteristics and handles them transparently for the user.</div></div><div id='stacks_out_1332_page0' class='stacks_out'><div id='stacks_in_1332_page0' class='stacks_in text_stack'><a href="papers/patraco.pdf">[pdf]</a> <a href="papers/patraco.bib">[bibtex]</a></div></div></div></div></div></div></div></div></div></div><div id='stacks_out_1083_page0' class='stacks_out'><div id='stacks_in_1083_page0' class='stacks_in text_stack'><span id='stacks_in_1084_page0'>2009</span></div></div><div id='stacks_out_521_page0' class='stacks_out'><div id='stacks_in_521_page0' class='stacks_in '><div id='stacks_out_522_page0' class='stacks_out'><div id='stacks_in_522_page0' class='stacks_in stack_stack'><div id='stacks_out_524_page0' class='stacks_out'><div id='stacks_in_524_page0' class='stacks_in stack_stack'><div id='stacks_out_526_page0' class='stacks_out'><div id='stacks_in_526_page0' class='stacks_in stack_stack'><div id='stacks_out_528_page0' class='stacks_out'><div id='stacks_in_528_page0' class='stacks_in image_stack'><div class='centered_image' ><img class='imageStyle' src='files/stacks_image_529.png' width='402' height='220' alt='Stacks Image 529' /></div></div></div></div></div><div id='stacks_out_530_page0' class='stacks_out'><div id='stacks_in_530_page0' class='stacks_in stack_stack'><div id='stacks_out_532_page0' class='stacks_out'><div id='stacks_in_532_page0' class='stacks_in text_stack'><span id='stacks_in_533_page0'><strong>Accelerating Raycasting Utilizing Volume Segmentation of Industrial CT Data</strong></span></div></div><div id='stacks_out_534_page0' class='stacks_out'><div id='stacks_in_534_page0' class='stacks_in text_stack'><em>S. Frey and T. Ertl</em></div></div><div id='stacks_out_536_page0' class='stacks_out'><div id='stacks_in_536_page0' class='stacks_in text_stack'><A TARGET="new" HREF="http://www.eguk.org.uk/TPCG09/">EG UK Theory and Practice of Computer Graphics (TPCG'09)</A>, Cardiff, Wales , 2008.</div></div><div id='stacks_out_538_page0' class='stacks_out'><div id='stacks_in_538_page0' class='stacks_in text_stack'>Raycasting large CT volumes interactively is still computationally demanding. Utilizing the segmentation information that is typically employed for object analysis, GPU ray casting can be accelerated significantly using a novel data structure that is integrated into the volume, requiring no extra texture lookups.</div></div><div id='stacks_out_540_page0' class='stacks_out'><div id='stacks_in_540_page0' class='stacks_in text_stack'><a href="papers/accel.pdf">[pdf]</a> <a href="papers/accel.bib">[bibtex]</a></div></div></div></div></div></div></div></div></div></div><div id='stacks_out_605_page0' class='stacks_out'><div id='stacks_in_605_page0' class='stacks_in '><div id='stacks_out_606_page0' class='stacks_out'><div id='stacks_in_606_page0' class='stacks_in stack_stack'><div id='stacks_out_608_page0' class='stacks_out'><div id='stacks_in_608_page0' class='stacks_in stack_stack'><div id='stacks_out_610_page0' class='stacks_out'><div id='stacks_in_610_page0' class='stacks_in stack_stack'><div id='stacks_out_926_page0' class='stacks_out'><div id='stacks_in_926_page0' class='stacks_in image_stack'><div class='centered_image' ><img class='imageStyle' src='files/stacks_image_927.png' width='292' height='220' alt='Stacks Image 927' /></div></div></div></div></div><div id='stacks_out_614_page0' class='stacks_out'><div id='stacks_in_614_page0' class='stacks_in stack_stack'><div id='stacks_out_616_page0' class='stacks_out'><div id='stacks_in_616_page0' class='stacks_in text_stack'><span id='stacks_in_617_page0'><strong>Concurrent CT Reconstruction and Visual Analysis Using Hybrid Multi-resolution Raycasting in a Cluster Environment</strong></span></div></div><div id='stacks_out_618_page0' class='stacks_out'><div id='stacks_in_618_page0' class='stacks_in text_stack'><em>S. Frey, C. M&uuml;ller, M. Strengert, and T. Ertl</em></div></div><div id='stacks_out_620_page0' class='stacks_out'><div id='stacks_in_620_page0' class='stacks_in text_stack'><A TARGET="new" HREF="http://www.isvc.net/09/">5th International Symposium on Advances in Visual Computing (ISVC'09)</A>, Las Vegas, Nevada, 2009.</div></div><div id='stacks_out_622_page0' class='stacks_out'><div id='stacks_in_622_page0' class='stacks_in text_stack'>Preparing the data for analysis after the CT scanning of an object takes a considerable amount of time. Our distributed program architecture leverages all resources of a GPU cluster for the incremental reconstruction, segmentation and rendering, provide the user with continuously updated provisional results.</div></div><div id='stacks_out_624_page0' class='stacks_out'><div id='stacks_in_624_page0' class='stacks_in text_stack'><a href="papers/concurrent.pdf">[pdf]</a> <a href="papers/concurrent.bib">[bibtex]</a></div></div></div></div></div></div></div></div></div></div><div id='stacks_out_773_page0' class='stacks_out'><div id='stacks_in_773_page0' class='stacks_in '><div id='stacks_out_774_page0' class='stacks_out'><div id='stacks_in_774_page0' class='stacks_in stack_stack'><div id='stacks_out_776_page0' class='stacks_out'><div id='stacks_in_776_page0' class='stacks_in stack_stack'><div id='stacks_out_778_page0' class='stacks_out'><div id='stacks_in_778_page0' class='stacks_in stack_stack'><div id='stacks_out_780_page0' class='stacks_out'><div id='stacks_in_780_page0' class='stacks_in image_stack'><div class='centered_image' ><img class='imageStyle' src='files/stacks_image_781.png' width='230' height='220' alt='Stacks Image 781' /></div></div></div></div></div><div id='stacks_out_782_page0' class='stacks_out'><div id='stacks_in_782_page0' class='stacks_in stack_stack'><div id='stacks_out_784_page0' class='stacks_out'><div id='stacks_in_784_page0' class='stacks_in text_stack'><span id='stacks_in_785_page0'><strong>CUDA-Accelerated Continuous 2-D Scatterplots</strong></span></div></div><div id='stacks_out_786_page0' class='stacks_out'><div id='stacks_in_786_page0' class='stacks_in text_stack'><em>S. Bachthaler, S. Frey and D. Weiskopf </em></div></div><div id='stacks_out_788_page0' class='stacks_out'><div id='stacks_in_788_page0' class='stacks_in text_stack'><A TARGET="new" HREF="http://vis.computer.org/VisWeek2009/vis/">IEEE Visualization 2009 (VIS'09)</A>, <em>Poster</em>, Atlantic City, USA, 2009.</div></div><div id='stacks_out_790_page0' class='stacks_out'><div id='stacks_in_790_page0' class='stacks_in text_stack'>Continuous scatterplots represent a continous distribution function in a dense way in the scatterplot domain. We significantly speed up the original CPU approach with our GPU implementation to allow for interactive exploration.</div></div><div id='stacks_out_792_page0' class='stacks_out'><div id='stacks_in_792_page0' class='stacks_in text_stack'><a href="papers/continuous_poster.pdf">[pdf]</a></div></div></div></div></div></div></div></div></div></div><div id='stacks_out_303_page0' class='stacks_out'><div id='stacks_in_303_page0' class='stacks_in '><div id='stacks_out_304_page0' class='stacks_out'><div id='stacks_in_304_page0' class='stacks_in stack_stack'><div id='stacks_out_306_page0' class='stacks_out'><div id='stacks_in_306_page0' class='stacks_in stack_stack'><div id='stacks_out_308_page0' class='stacks_out'><div id='stacks_in_308_page0' class='stacks_in stack_stack'><div id='stacks_out_310_page0' class='stacks_out'><div id='stacks_in_310_page0' class='stacks_in image_stack'><div class='centered_image' ><img class='imageStyle' src='files/stacks_image_311.png' width='310' height='168' alt='Stacks Image 311' /></div></div></div></div></div><div id='stacks_out_312_page0' class='stacks_out'><div id='stacks_in_312_page0' class='stacks_in stack_stack'><div id='stacks_out_314_page0' class='stacks_out'><div id='stacks_in_314_page0' class='stacks_in text_stack'><span id='stacks_in_315_page0'><strong>A Compute Unified System Architecture for Graphics Clusters Incorporating Data-Locality</strong></span></div></div><div id='stacks_out_316_page0' class='stacks_out'><div id='stacks_in_316_page0' class='stacks_in text_stack'><em>C. M&uuml;ller, S. Frey, M. Strengert, C. Dachsbacher and T. Ertl</em></div></div><div id='stacks_out_318_page0' class='stacks_out'><div id='stacks_in_318_page0' class='stacks_in text_stack'><A TARGET="new" HREF="www.computer.org/tvcg">IEEE Transactions on Visualization and Computer Graphics (TVCG)</A>, 2009</div></div><div id='stacks_out_320_page0' class='stacks_out'><div id='stacks_in_320_page0' class='stacks_in text_stack'>CUDA is a parallel computing architecture for graphics cards. CUDASA logically extends its programming model and API for multi-GPU systems and distributed GPU computing. It includes an automatic GPU-accelerated scheduling mechanism that is aware of data locality to optimize GPU utilization.</div></div><div id='stacks_out_322_page0' class='stacks_out'><div id='stacks_in_322_page0' class='stacks_in text_stack'><a href="papers/cudasa.pdf">[pdf]</a> <a href="papers/cudasa.bib">[bibtex]</a></div></div></div></div></div></div></div></div></div></div><div id='stacks_out_196_page0' class='stacks_out'>

			      <!-- <div id='stacks_in_196_page0' class='stacks_in text_stack'><span id='stacks_in_195_page0'><a name="service">Service</a></span></div></div><div id='stacks_out_997_page0' class='stacks_out'><div id='stacks_in_997_page0' class='stacks_in text_stack'><ul class="disc"> -->
			    <!-- 	  <li>Program Committee Member, Euromicro Conference on Software Engineering and Advanced Applications (Special Session on Software Analytics), 2018.</li> -->
			    <!-- 	  <li>Member of Technical Program Committee, Supercomputing ASIA, 2018.</li>				   -->
			    <!-- 	  <li>Program Committee Member, Symposium on Large Data Analysis and Visualization (LDAV), 2017.</li> -->
			    <!-- 	  <li>Program Committee Member, EuroVIS (short papers), 2017.</li> -->
			    <!-- 	  <li>Program Committee Member, SIGGRAPH ASIA Symposium on Visualization, 2017.</li> -->
			    <!-- 	  <li>Program Committee Member, International Symposium on Visual Computing (ISVC), 2017.</li> -->
			    <!-- 	  <li>Program Committee Member, EuroVIS Short Papers, 2017.</li> -->
			    <!-- 	  <li>Program Committee Member, ISC, 2017.</li> -->
			    <!-- 	  <li>Chair, ISC Workshop on In Situ Visualization, 2016.</li> -->
			    <!-- 	  <li>Program Committee Member, Symposium on Large Data Analysis and Visualization (LDAV), 2016.</li> -->
			    <!-- 	  <li>Program Committee Member, SIGGRAPH ASIA Symposium on Visualization, 2016.</li> -->
			    <!-- 	  <li>Program Committee Member, International Symposium on Visual Computing (ISVC), 2016.</li> -->
			    <!-- </ul></div></div> -->

			    <!-- <div id='stacks_out_199_page0' class='stacks_out'><div id='stacks_in_199_page0' class='stacks_in text_stack'><span id='stacks_in_200_page0'><a name="teaching">Teaching</a></span></div></div><div id='stacks_out_800_page0' class='stacks_out'><div id='stacks_in_800_page0' class='stacks_in text_stack'><span id='stacks_in_801_page0'><strong>Advised Student Bachelor/Master/Diploma Theses</strong></span></div></div><div id='stacks_out_804_page0' class='stacks_out'><div id='stacks_in_804_page0' class='stacks_in text_stack'><ul class="disc"> -->
			    <!-- 	  <li><strong>Machine Learning-based analysis of droplet behavior in multiphase flow simulations</strong>, Moritz Heinemann, 2018.</li> -->
			    <!-- 	  <li><strong>Analysis of spatiotemporal ensemble data using machine learning</strong>, Stefan Scheller, 2017/18.</li> -->
			    <!-- 	  <li><strong>Encoding quality prediction for interactive remote visualisation</strong>, Mathias Landwehr, 2017/18.</li> -->
			    <!-- 	  <li><strong>Investigation of Volume Rendering Performance through Active Learning and Visual Analysis</strong>, Stephan Roth, 2017.</li> -->
			    <!-- 	  <li><strong>Investigation of State-of-the-Art Compression Algorithms for Densely Recorded Light Fields</strong>, Clemens Sigel, 2017.</li> -->
			    <!-- 	  <li><strong>Progressive Sparse Coding for In Situ Volume Visualisation</strong>, Gratian Berian, 2016/16.</li> -->
			    <!-- 	  <li><strong>Investigation and prediction of distributed volume rendering performance</strong>, Gleb Tkachev, 2016/17.</li> -->
			    <!-- 	  <li><strong>Performance Quantification of Volume Visualization</strong>, Valentin Bruder, 2015/16.</li> -->
			    <!-- 	  <li><strong>Real-time Ray Tracing of Volumetric Data</strong>, Marcus Richter, 2015/16.</li><li><strong>Dynamic Acceleration Structures for the Visualization of Time-Dependent Volume Data on the GPU</strong>, Hajun Jang, 2014/15.</li><li><strong>Adaptive Frameless Raycasting for Interactive Volume Visualization</strong>, Constantin Weisser, 2014.</li><li><strong>Extraction of High Quality Isosurfaces from Large Volume Data</strong>, Thomas Mezger, 2012/13.</li><li><strong>Distributed Raytracing on GPU Clusters</strong>, Jochen Puff, 2010.</li><li><strong>Algorithm Design and Algorithmic-Level Optimization of Video / Image Algorithm using an Abstract Common Interface for NVIDIA CUDA and Intel Larrabee Platforms</strong>, Daniel Kauker, 2009/2010.</li><li><strong>Parallel Computation of Volumetric Illumination of Astrophysical Nebulae on GPU Clusters</strong>, Manuel Moser, 2009/2010.</li></ul></div></div> -->

			    <!-- <div id='stacks_out_796_page0' class='stacks_out'><div id='stacks_in_796_page0' class='stacks_in text_stack'><span id='stacks_in_797_page0'><strong>Courses</strong></span></div></div><div id='stacks_out_194_page0' class='stacks_out'><div id='stacks_in_194_page0' class='stacks_in text_stack'><ul class="disc"> -->
			    <!-- 	  <li>Advanced Seminar: Multifield Visualization, 2017/18</li> -->
			    <!-- 	  <li>SimTech Seminar, 2017/18</li> -->
			    <!-- 	  <li>Lecture: Scientific Visualization, 2017</li> -->
			    <!-- 	  <li>Advanced Seminar: High-Performance Visualization, 2016/17</li> -->
			    <!-- 	  <li>Lecture: Scientific Visualization, 2016</li> -->
			    <!-- 	  <li>Lecture: Scientific Visualization, 2015</li> -->
			    <!-- 	  <li>...</li> -->
			    <!-- 	  <li>Hauptseminar Advanced Visualization Techniques, 2012/13</li> -->
			    <!-- 	  <li>Hauptseminar Volume Rendering, 2011/12</li> -->
			    <!-- 	  <li>Seminar Interactive Visualization Techniques, 2011</li><li>Hauptseminar Volume Rendering, 2010</li><li>Lecture Assignments Visual Computing, 2009/10</li><li>Lecture Assignments Image Synthesis/Rendering, 2009</li><li>Lecture Assignments Visual Computing, 2008/09</li><li>Graphics and GPU programming lab, 2008/09</li></ul></div></div> -->


			    <!-- <div id='stacks_out_812_page0' class='stacks_out'><div id='stacks_in_812_page0' class='stacks_in text_stack'><span id='stacks_in_813_page0'> -->
			    <!-- 	  <a name="selected">Selected Projects as a Student</a></span></div></div><div id='stacks_out_835_page0' class='stacks_out'><div id='stacks_in_835_page0' class='stacks_in '><div id='stacks_out_836_page0' class='stacks_out'><div id='stacks_in_836_page0' class='stacks_in stack_stack'><div id='stacks_out_838_page0' class='stacks_out'><div id='stacks_in_838_page0' class='stacks_in stack_stack'><div id='stacks_out_840_page0' class='stacks_out'><div id='stacks_in_840_page0' class='stacks_in stack_stack'><div id='stacks_out_842_page0' class='stacks_out'><div id='stacks_in_842_page0' class='stacks_in image_stack'><div class='centered_image' ><img class='imageStyle' src='files/stacks_image_843.png' width='248' height='220' alt='Stacks Image 843' /></div></div></div></div></div><div id='stacks_out_844_page0' class='stacks_out'><div id='stacks_in_844_page0' class='stacks_in stack_stack'><div id='stacks_out_846_page0' class='stacks_out'><div id='stacks_in_846_page0' class='stacks_in text_stack'><span id='stacks_in_847_page0'><strong>GPU-basierte Kegelstrahlrekonstruktion gro&szlig;er CT Datensätze</strong></span></div></div><div id='stacks_out_7_page0' class='stacks_out'><div id='stacks_in_7_page0' class='stacks_in text_stack'><em>Advisiors: Magnus Strengert (VISUS), Rolf Schaller (Daimler AG)</em></div></div><div id='stacks_out_852_page0' class='stacks_out'><div id='stacks_in_852_page0' class='stacks_in text_stack'>CT reconstruction plays an important role in industrial material testing and quality control. However, this process step can take considerable time, thus delaying the overall workflow.<br />The work introduces and evaluates several approaches for accelerating the Feldkamp CT reconstruction algorithm using a GPU.</div></div></div></div></div></div></div></div></div></div><div id='stacks_out_873_page0' class='stacks_out'><div id='stacks_in_873_page0' class='stacks_in '><div id='stacks_out_874_page0' class='stacks_out'><div id='stacks_in_874_page0' class='stacks_in stack_stack'><div id='stacks_out_876_page0' class='stacks_out'><div id='stacks_in_876_page0' class='stacks_in stack_stack'><div id='stacks_out_878_page0' class='stacks_out'><div id='stacks_in_878_page0' class='stacks_in stack_stack'><div id='stacks_out_880_page0' class='stacks_out'><div id='stacks_in_880_page0' class='stacks_in image_stack'><div class='centered_image' ><img class='imageStyle' src='files/stacks_image_881.png' width='500' height='220' alt='Stacks Image 881' /></div></div></div></div></div><div id='stacks_out_882_page0' class='stacks_out'><div id='stacks_in_882_page0' class='stacks_in stack_stack'><div id='stacks_out_884_page0' class='stacks_out'><div id='stacks_in_884_page0' class='stacks_in text_stack'><span id='stacks_in_885_page0'><strong>Depth Peeling in OpenSceneGraph</strong></span></div></div><div id='stacks_out_886_page0' class='stacks_out'><div id='stacks_in_886_page0' class='stacks_in text_stack'>Depth peeling extracts 2D layers of 3D geometry in depth-sorted order. I implemented this technique as final project for the Graphics and GPU programming lab. I also added some sketchy drawing outline modes to generate the look of hand-drawn sketches. It was submitted to the <a href="http://www.openscenegraph.org">OpenSceneGraph</a> project and is contained in the package as the <em>osgdepthpeeeling example.</em></div></div></div></div></div></div></div></div></div></div><div id='stacks_out_28_page0' class='stacks_out'><div id='stacks_in_28_page0' class='stacks_in '><div id='stacks_out_29_page0' class='stacks_out'><div id='stacks_in_29_page0' class='stacks_in stack_stack'><div id='stacks_out_31_page0' class='stacks_out'><div id='stacks_in_31_page0' class='stacks_in stack_stack'><div id='stacks_out_33_page0' class='stacks_out'><div id='stacks_in_33_page0' class='stacks_in stack_stack'><div id='stacks_out_35_page0' class='stacks_out'><div id='stacks_in_35_page0' class='stacks_in image_stack'><div class='centered_image' ><img class='imageStyle' src='files/stacks_image_36.png' width='294' height='220' alt='Stacks Image 36' /></div></div></div></div></div><div id='stacks_out_37_page0' class='stacks_out'><div id='stacks_in_37_page0' class='stacks_in stack_stack'><div id='stacks_out_39_page0' class='stacks_out'><div id='stacks_in_39_page0' class='stacks_in text_stack'><span id='stacks_in_40_page0'><strong>Webservice-Based Remote Rendering</strong></span></div></div><div id='stacks_out_41_page0' class='stacks_out'><div id='stacks_in_41_page0' class='stacks_in text_stack'>I was working on a web-based service for rendering medical volumetric data sets as a research assistant of <a href="www.vis.uni-stuttgart.de/~roessler/">Friedemann R&ouml;&szlig;ler</a> at the VIS .</div></div></div></div></div></div></div></div></div></div><div id='stacks_out_907_page0' class='stacks_out'><div id='stacks_in_907_page0' class='stacks_in '><div id='stacks_out_908_page0' class='stacks_out'><div id='stacks_in_908_page0' class='stacks_in stack_stack'><div id='stacks_out_910_page0' class='stacks_out'><div id='stacks_in_910_page0' class='stacks_in stack_stack'><div id='stacks_out_912_page0' class='stacks_out'><div id='stacks_in_912_page0' class='stacks_in stack_stack'><div id='stacks_out_914_page0' class='stacks_out'><div id='stacks_in_914_page0' class='stacks_in image_stack'><div class='centered_image' ><img class='imageStyle' src='files/stacks_image_915.png' width='290' height='136' alt='Stacks Image 915' /></div></div></div></div></div><div id='stacks_out_916_page0' class='stacks_out'><div id='stacks_in_916_page0' class='stacks_in stack_stack'><div id='stacks_out_918_page0' class='stacks_out'><div id='stacks_in_918_page0' class='stacks_in text_stack'><span id='stacks_in_919_page0'><strong>Extending a Multimedia Engine for  3d madness GmbH</strong></span></div></div><div id='stacks_out_920_page0' class='stacks_out'><div id='stacks_in_920_page0' class='stacks_in text_stack'><A TARGET="new" HREF="http://www.3dmadness.de">3d madness</A> is a multimedia studio, with focus on the 3D Visualization of products, buildings and data as well ass virtual reality amongst others. I was working on making a powerful open source multimedia engine (<A TARGET="new" HREF="http://www.delta3d.org">Delta3D</A>) accessible for the 3D modelers and designers as well as integrating effects (e.g. shadows) according to their needs.<br /></div></div></div></div></div></div></div></div></div></div></div></div> -->



<!-- End of Stacks Content -->



			<div class="clear"></div>
			<div class="clearer"></div>
		</div><!-- End content -->
	</div><!-- End main content wrapper -->

	<div class="clearer"></div>
	<div id="footer"><!-- Start Footer -->
		<div id="breadcrumbcontainer"><!-- Start the breadcrumb wrapper -->

		</div><!-- End breadcrumb -->
		<!-- <p>Last Update 08.04.2015</p> -->
		<p>Have a nice day!</p>
	</div><!-- End Footer -->
</div><!-- End container -->
</body>
</html>
